{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_827671/2155073882.py:10: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import gaussian_filter\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Module to detect spindles.\n",
    "\"\"\"\n",
    "from logging import getLogger\n",
    "from numpy import (absolute, arange, argmax, argmin, around, asarray, \n",
    "                   concatenate, cos, diff, exp, empty, histogram, \n",
    "                   hstack, insert, invert, log10, logical_and, mean, median, \n",
    "                   nan, ones, percentile, pi, ptp, real, sqrt, square, std, \n",
    "                   sum, vstack, where, zeros)\n",
    "from numpy.fft import rfftfreq\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.signal import (argrelmax, butter, cheby2, filtfilt, \n",
    "                          fftconvolve, hilbert, periodogram, remez, \n",
    "                          sosfiltfilt, spectrogram, tukey)\n",
    "from scipy.fftpack import next_fast_len\n",
    "\n",
    "\n",
    "lg = getLogger(__name__)\n",
    "MAX_FREQUENCY_OF_INTEREST = 50\n",
    "MAX_DURATION = 10\n",
    "\n",
    "\n",
    "class DetectSpindle:\n",
    "    \"\"\"Design spindle detection on a single channel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str\n",
    "        one of the predefined methods\n",
    "    frequency : tuple of float\n",
    "        low and high frequency of spindle band\n",
    "    duration : tuple of float\n",
    "        min and max duration of spindles\n",
    "    merge : bool\n",
    "        if True, then after events are detected on every channel, events on \n",
    "        different channels that are separated by less than min_interval will be \n",
    "        merged into a single event, with 'chan' = the chan of the earlier-onset \n",
    "        event.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    tolerance : float\n",
    "        during detection and prior to applying the duration criterion, \n",
    "        candidate events separated by less than this time interval are merged. \n",
    "        In this way, the detector becomes tolerant to short dips below the \n",
    "        eligibility threshold (e.g. if the spindle power drops for a split \n",
    "        second).\n",
    "    min_interval : float\n",
    "        after the duration criterion is applied, events separated by less than\n",
    "        this interval are merged into a single event, with 'chan' = the chan\n",
    "        of the earlier-onset event.\n",
    "    power_peaks : str or None\n",
    "        for peak power statistics. 'peak' or 'interval'. If None, values will \n",
    "        all be NaN\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    See individual detect_* functions for other attribute descriptions.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='Moelle2011', frequency=None, duration=None,\n",
    "                 merge=False):\n",
    "        \n",
    "        self.method = method\n",
    "        self.frequency = frequency\n",
    "        self.merge = merge\n",
    "        self.tolerance = 0\n",
    "        self.min_interval = 0\n",
    "        self.power_peaks = 'interval'\n",
    "        self.rolloff = None\n",
    "        \n",
    "        if method == 'Ferrarelli2007':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (11, 15)\n",
    "            self.duration = (0.3, 3)\n",
    "            self.det_remez = {'freq': self.frequency,\n",
    "                              'rolloff': 0.9,\n",
    "                              'dur': 2.56\n",
    "                              }\n",
    "            self.det_thresh = 8\n",
    "            self.sel_thresh = 2\n",
    "            \n",
    "        elif method == 'Moelle2011':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (12, 15)\n",
    "            self.duration = (0.5, 3)\n",
    "            self.det_remez = {'freq': self.frequency,\n",
    "                              'rolloff': 1.7,\n",
    "                              'dur': 2.36\n",
    "                               }\n",
    "            self.moving_rms = {'dur': .2,\n",
    "                               'step': None}\n",
    "            self.smooth = {'dur': .2,\n",
    "                           'win': 'flat'}\n",
    "            self.det_thresh = 1.5\n",
    "            \n",
    "        elif method == 'Nir2011':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (9.2, 16.8)\n",
    "            self.duration = (0.5, 2)\n",
    "            self.det_butter = {'order': 2,\n",
    "                               'freq': self.frequency,\n",
    "                               }\n",
    "            self.tolerance = 1\n",
    "            self.smooth = {'dur': .04}  # is in fact sigma\n",
    "            self.det_thresh = 3\n",
    "            self.sel_thresh = 1\n",
    "            \n",
    "            \n",
    "        elif method == 'Wamsley2012':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (12, 15)\n",
    "            self.duration = (0.3, 3)\n",
    "            self.det_wavelet = {'f0': mean(self.frequency),\n",
    "                                'sd': .8,\n",
    "                                'dur': 1.,\n",
    "                                'output': 'complex'\n",
    "                                }\n",
    "            self.smooth = {'dur': .1,\n",
    "                           'win': 'flat'}\n",
    "            self.det_thresh = 4.5\n",
    "\n",
    "        elif method == 'Martin2013':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (11.5, 14.5)\n",
    "            self.duration = (.5, 3)\n",
    "            self.det_remez = {'freq': self.frequency,\n",
    "                              'rolloff': 1.1,\n",
    "                              'dur': 2.56\n",
    "                               }\n",
    "            self.moving_rms = {'dur': .25,\n",
    "                               'step': .25}\n",
    "            self.det_thresh = 95\n",
    "            \n",
    "        elif method == 'Ray2015':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (11, 16)\n",
    "            self.duration = (.49, None)\n",
    "            self.cdemod = {'freq': mean(self.frequency)}\n",
    "            self.det_butter = {'freq': (0.3, 35),\n",
    "                               'order': 4}\n",
    "            self.det_low_butter = {'freq': 5,\n",
    "                                   'order': 4}\n",
    "            self.min_interval = 0.25 # they only start looking again after .25s\n",
    "            self.smooth = {'dur': 2 / self.cdemod['freq'],\n",
    "                           'win': 'triangle'}\n",
    "            self.zscore = {'dur': 60,\n",
    "                           'step': None,\n",
    "                           'pcl_range': None}\n",
    "            self.det_thresh = 2.33\n",
    "            self.sel_thresh = 0.1\n",
    "        \n",
    "        elif method == 'Lacourse2018':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (11, 16)\n",
    "            self.duration = (.3, 2.5)\n",
    "            self.det_butter = {'freq': self.frequency,\n",
    "                               'order': 20}\n",
    "            self.det_butter2 = {'freq': (.3, 30),\n",
    "                                'order': 5}\n",
    "            self.windowing = win = {'dur': .3,\n",
    "                                    'step': .1}\n",
    "            self.moving_ms = {'dur': win['dur'],\n",
    "                              'step': win['step']}\n",
    "            self.moving_power_ratio = {'dur': win['dur'],\n",
    "                                     'step': win['step'],\n",
    "                                     'freq_narrow': self.frequency,\n",
    "                                     'freq_broad': (4.5, 30),\n",
    "                                     'fft_dur': 2}\n",
    "            self.zscore = {'dur': 30,\n",
    "                           'step': None,\n",
    "                           'pcl_range': (10, 90)}\n",
    "            self.moving_covar = {'dur': win['dur'],\n",
    "                                 'step': win['step']}\n",
    "            self.moving_sd = {'dur': win['dur'],\n",
    "                              'step': win['step']}\n",
    "            self.smooth = {'dur': 0.3,\n",
    "                           'win': 'flat_left'}\n",
    "            self.abs_pow_thresh = 1.25\n",
    "            self.rel_pow_thresh = 1.6\n",
    "            self.covar_thresh = 1.3\n",
    "            self.corr_thresh = 0.69\n",
    "        \n",
    "        elif 'FASST' in method:\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (11, 18)\n",
    "            self.duration = (.4, 1.3)\n",
    "            self.det_butter = {'freq': self.frequency,\n",
    "                               'order': 4}\n",
    "            self.min_interval = 1\n",
    "            self.moving_rms = {'dur': .1,\n",
    "                               'step': None}\n",
    "            self.smooth = {'dur': .1,\n",
    "                           'win': 'flat'}\n",
    "            self.det_thresh = 90\n",
    "        \n",
    "        elif method == 'UCSD':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (10, 16)\n",
    "            self.duration = (0.3, 3)\n",
    "            self.det_wavelet = {'freqs': arange(self.frequency[0],\n",
    "                                                self.frequency[1] + .5, .5),\n",
    "                                'dur': 1,\n",
    "                                'width': .5,\n",
    "                                'win': .5,\n",
    "                                'sd': None\n",
    "                                }\n",
    "            self.det_thresh = 2  # wavelet_peak_thresh\n",
    "            self.sel_wavelet = {'freqs': arange(self.frequency[0],\n",
    "                                                self.frequency[1] + .5, .5),\n",
    "                                'dur': 1,\n",
    "                                'width': .2,\n",
    "                                'win': .2,\n",
    "                                }\n",
    "            self.sel_thresh = 1\n",
    "            self.ratio_thresh = .5\n",
    "\n",
    "        elif method == 'Concordia':\n",
    "            if self.frequency is None:\n",
    "                self.frequency = (10, 16)\n",
    "            self.duration = (0.5, 3)\n",
    "            self.det_butter = {'order': 2,\n",
    "                               'freq': self.frequency,\n",
    "                               }\n",
    "            self.moving_rms = {'dur': .2,\n",
    "                               'step': None}\n",
    "            self.smooth = {'dur': .2,\n",
    "                           'win': 'flat'}\n",
    "            self.det_thresh = 3\n",
    "            self.det_thresh_hi = 10\n",
    "            self.tolerance = 0.2\n",
    "            self.sel_thresh = 1\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('Unknown method')\n",
    "            \n",
    "        if frequency is not None:\n",
    "            self.frequency = frequency\n",
    "        \n",
    "        if duration is not None:\n",
    "            self.duration = duration\n",
    "\n",
    "    def __repr__(self):\n",
    "        return ('detsp_{0}_{1:02}-{2:02}Hz_{3:04.1f}-{4:04.1f}s'\n",
    "                ''.format(self.method, self.frequency[0], self.frequency[1],\n",
    "                          self.duration[0], self.duration[1]))\n",
    "\n",
    "    def __call__(self, data, parent=None):\n",
    "        \"\"\"Detect spindles on the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : instance of Data\n",
    "            data used for detection\n",
    "        parent : QWidget\n",
    "            for use with GUI, as parent widget for the progress bar\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        instance of graphoelement.Spindles\n",
    "            description of the detected spindles\n",
    "        \"\"\"\n",
    "        if parent is not None:\n",
    "            progress = QProgressDialog('Finding spindles', 'Abort', \n",
    "                                       0, data.number_of('chan')[0], parent)\n",
    "            progress.setWindowModality(Qt.ApplicationModal)\n",
    "        \n",
    "        spindle = Spindles()\n",
    "        spindle.chan_name = data.axis['chan'][0]\n",
    "        spindle.det_values = empty(data.number_of('chan')[0], dtype='O')\n",
    "        spindle.density = zeros(data.number_of('chan')[0])\n",
    "        \n",
    "        if self.duration[1] is None:\n",
    "            self.duration = self.duration[0], MAX_DURATION\n",
    "\n",
    "        all_spindles = []\n",
    "        i = 0\n",
    "        for i, chan in enumerate(data.axis['chan'][0]):\n",
    "                \n",
    "            lg.info('Detecting spindles on channel %s', chan)\n",
    "            time = hstack(data.axis['time'])\n",
    "            dat_orig = hstack(data(chan=chan))\n",
    "            dat_orig = dat_orig - dat_orig.mean() # demean\n",
    "\n",
    "            if self.method == 'Ferrarelli2007':\n",
    "                sp_in_chan, values, density = detect_Ferrarelli2007(dat_orig,\n",
    "                                                                    data.s_freq,\n",
    "                                                                    time,\n",
    "                                                                    self)\n",
    "                \n",
    "            elif self.method == 'Moelle2011':\n",
    "                sp_in_chan, values, density = detect_Moelle2011(dat_orig,\n",
    "                                                                data.s_freq,\n",
    "                                                                time, self)\n",
    "                \n",
    "            elif self.method == 'Nir2011':\n",
    "                sp_in_chan, values, density = detect_Nir2011(dat_orig,\n",
    "                                                             data.s_freq,\n",
    "                                                             time, self)\n",
    "                \n",
    "                \n",
    "            elif self.method == 'Wamsley2012':\n",
    "                sp_in_chan, values, density = detect_Wamsley2012(dat_orig,\n",
    "                                                                 data.s_freq,\n",
    "                                                                 time, self)\n",
    "                \n",
    "            elif self.method == 'Martin2013':\n",
    "                sp_in_chan, values, density = detect_Martin2013(dat_orig,\n",
    "                                                                data.s_freq,\n",
    "                                                                time, self)\n",
    "                \n",
    "            elif self.method == 'Ray2015':\n",
    "                sp_in_chan, values, density = detect_Ray2015(dat_orig,\n",
    "                                                            data.s_freq,\n",
    "                                                            time, self)\n",
    "                \n",
    "            elif self.method == 'Lacourse2018':\n",
    "                sp_in_chan, values, density = detect_Lacourse2018(dat_orig,\n",
    "                                                                  data.s_freq,\n",
    "                                                                  time, self)    \n",
    "                \n",
    "            elif self.method == 'FASST':\n",
    "                sp_in_chan, values, density = detect_FASST(dat_orig,\n",
    "                                                           data.s_freq,\n",
    "                                                           time, self,\n",
    "                                                           submethod='abs')\n",
    "                \n",
    "            elif self.method == 'FASST2':\n",
    "                sp_in_chan, values, density = detect_FASST(dat_orig,\n",
    "                                                           data.s_freq,\n",
    "                                                           time, self,\n",
    "                                                           submethod='rms')\n",
    "                \n",
    "            elif self.method == 'UCSD':\n",
    "                sp_in_chan, values, density = detect_UCSD(dat_orig,\n",
    "                                                          data.s_freq, time,\n",
    "                                                          self)\n",
    "                \n",
    "            elif self.method == 'Concordia':\n",
    "                sp_in_chan, values, density = detect_Concordia(dat_orig,\n",
    "                                                               data.s_freq,\n",
    "                                                               time, self)\n",
    "                \n",
    "            else:\n",
    "                raise ValueError('Unknown method')\n",
    "\n",
    "            spindle.det_values[i] = values\n",
    "            spindle.density[i] = density\n",
    "\n",
    "            for sp in sp_in_chan:\n",
    "                sp.update({'chan': chan})\n",
    "\n",
    "            all_spindles.extend(sp_in_chan)\n",
    "            \n",
    "            if parent is not None:\n",
    "                progress.setValue(i)\n",
    "                if progress.wasCanceled():\n",
    "                    return\n",
    "            # end of loop over chan\n",
    "\n",
    "        spindle.events = sorted(all_spindles, key=lambda x: x['start'])\n",
    "        lg.info(str(len(spindle.events)) + ' spindles detected.')\n",
    "\n",
    "        if self.merge and len(data.axis['chan'][0]) > 1:\n",
    "            spindle.events = merge_close(spindle.events, self.min_interval)\n",
    "\n",
    "        if parent is not None:\n",
    "            progress.setValue(i + 1)            \n",
    "        \n",
    "        return spindle\n",
    "\n",
    "\n",
    "def detect_Ferrarelli2007(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Ferrarelli et al. 2007, and scripts obtained\n",
    "    from Warby et al. (2014).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_remez' : dict\n",
    "            parameters for 'remez',\n",
    "        'det_thresh' : float\n",
    "            detection threshold\n",
    "        'sel_thresh' : float\n",
    "            selection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' with nan,\n",
    "        'sel_value' with selection value\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Ferrarelli, F. et al. Am. J. Psychiatry 164, 483-92 (2007).\n",
    "    Warby, S. C. et al. Nat. Meth. 11(4), 385-92 (2014).\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'remez', opts.det_remez)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'abs')\n",
    "    \n",
    "    idx_env = peaks_in_time(dat_det)\n",
    "    envelope = dat_det[idx_env]\n",
    "    idx_peak = idx_env[peaks_in_time(envelope)] # in raw data time\n",
    "    idx_trough = peaks_in_time(envelope, troughs=True) # in envelope time\n",
    "    troughs = ones(len(envelope)) * -1\n",
    "    troughs[idx_trough] = envelope[idx_trough] # all non-trough values are -1\n",
    "\n",
    "    det_value = define_threshold(dat_det, s_freq, 'mean', opts.det_thresh)\n",
    "    sel_value = define_threshold(dat_det[idx_peak], s_freq, 'histmax', \n",
    "                                 opts.sel_thresh, nbins=120)\n",
    "    \n",
    "    events_env = detect_events(envelope, 'above_thresh', det_value)\n",
    "    \n",
    "    if events_env is not None:\n",
    "        events_env = _merge_close(envelope, events_env, time[idx_env], \n",
    "                                  opts.tolerance)\n",
    "        events_env = select_events(troughs, events_env, \n",
    "                                   'Ferrarelli2007', sel_value)  \n",
    "        events = idx_env[events_env]\n",
    "        # merging is necessary, because detected spindles may overlap if the\n",
    "        # signal envelope does not dip below sel_thresh between two peaks above \n",
    "        # det_thresh\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = within_duration(events, time, opts.duration)        \n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                                   dat_orig, time, s_freq)\n",
    "        lg.info('Spindles in chan: ' + str(len(sp_in_chan)))\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': sel_value}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Moelle2011(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Moelle et al. 2011\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_remez' : dict\n",
    "            parameters for 'remez',\n",
    "        'moving_rms' : dict\n",
    "            parameters for 'moving_rms'\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'det_thresh' : float\n",
    "            detection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' with nan,\n",
    "        'sel_value' with nan\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Moelle, M. et al. J. Neurosci. 22(24), 10941-7 (2002).\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'remez', opts.det_remez)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'moving_rms', opts.moving_rms)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'smooth', opts.smooth)\n",
    "\n",
    "    det_value = define_threshold(dat_det, s_freq, 'mean+std',\n",
    "                                 opts.det_thresh)\n",
    "\n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "\n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': nan}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Nir2011(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Nir et al. 2011\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_butter' : dict\n",
    "            parameters for 'butter',\n",
    "        'smooth' : dict\n",
    "            parameters for 'gaussian'\n",
    "        'det_thresh' : float\n",
    "            detection threshold\n",
    "        'sel_thresh' : float\n",
    "            selection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' with nan,\n",
    "        'sel_value' with selection value\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This paper also selects channels carefully:\n",
    "    'First, the channels with spindle activity in NREM sleep were\n",
    "    chosen for further analysis.'\n",
    "\n",
    "    'Third, those channels, in which an increase in spectral power\n",
    "    within the detected events was restricted to the spindle-frequency\n",
    "    range (10-16 Hz) rather than broadband.'\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Nir, Y. et al. Neuron 70, 153-69 (2011).\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'butter', opts.det_butter)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'hilbert')\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'abs')\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'gaussian', opts.smooth)\n",
    "\n",
    "    det_value = define_threshold(dat_det, s_freq, 'mean+std',\n",
    "                                 opts.det_thresh)\n",
    "    sel_value = define_threshold(dat_det, s_freq, 'mean+std', opts.sel_thresh)\n",
    "\n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "\n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "        events = select_events(dat_det, events, 'above_thresh', sel_value)\n",
    "        \n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': sel_value}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Wamsley2012(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Wamsley et al. 2012\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_wavelet' : dict\n",
    "            parameters for 'morlet',\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'det_thresh' : float\n",
    "            detection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' is nan,\n",
    "        'sel_value' is nan (for consistency with other methods)\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Wamsley, E. J. et al. Biol. Psychiatry 71, 154-61 (2012).\n",
    "    \"\"\"\n",
    "    dat_wav = transform_signal(dat_orig, s_freq, 'morlet', opts.det_wavelet)\n",
    "    dat_det = real(dat_wav ** 2) ** 2\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'smooth', opts.smooth)\n",
    "\n",
    "    det_value = define_threshold(dat_det, s_freq, 'mean', opts.det_thresh)\n",
    "\n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "\n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, \n",
    "                                   absolute(dat_wav), dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': nan}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Martin2013(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Martin et al. 2013\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_remez' : dict\n",
    "             parameters for 'remez' filter\n",
    "        'moving_rms' : dict\n",
    "             parameters for 'moving_rms'\n",
    "        'det_thresh' : float\n",
    "            percentile for detection threshold\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' is nan,\n",
    "        'sel_value' is nan (for consistency with other methods)\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Martin, N. et al. Neurobio Aging 34(2), 468-76 (2013).\n",
    "    \"\"\"\n",
    "    dat_filt = transform_signal(dat_orig, s_freq, 'remez', opts.det_remez)\n",
    "    dat_det = transform_signal(dat_filt, s_freq, 'moving_rms', opts.moving_rms)\n",
    "        # downsampled\n",
    "    \n",
    "    det_value = percentile(dat_det, opts.det_thresh)\n",
    "    \n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "    \n",
    "    if events is not None:\n",
    "        events *= int(around(s_freq * opts.moving_rms['step'])) # upsample\n",
    "        events = _merge_close(dat_filt, events, time, opts.tolerance)\n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_filt, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_filt,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': nan}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Ray2015(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Ray et al., 2015\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'cdemod' : dict\n",
    "            parameters for 'cdemod' (complex demodulation)\n",
    "        'det_butter' : dict\n",
    "            parameters for 'butter',\n",
    "        'det_low_butter' : dict\n",
    "            parameters for 'low_butter',\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'zscore' : dict\n",
    "            parameters for 'moving_zscore'\n",
    "        'det_thresh' : float\n",
    "            detection threshold\n",
    "        'sel_thresh' : nan\n",
    "            selection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' is nan,\n",
    "        'sel_value' is nan (for consistency with other methods)\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Ray, L. B. et al. Front. Hum. Neurosci. 9-16 (2015).\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'butter', opts.det_butter)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'cdemod', opts.cdemod)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'low_butter', \n",
    "                               opts.det_low_butter)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'smooth', opts.smooth)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'abs_complex')\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'moving_zscore', opts.zscore)\n",
    "    \n",
    "    det_value = opts.det_thresh\n",
    "    sel_value = opts.sel_thresh\n",
    "    \n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "    \n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "        events = select_events(dat_det, events, 'above_thresh', sel_value)\n",
    "        \n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': sel_value}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Lacourse2018(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on Lacourse et al., 2018\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_butter' : dict\n",
    "            parameters for 'butter',\n",
    "        'det_butter2' : dict\n",
    "            parameters for 'butter',\n",
    "        'windowing' :\n",
    "            'step' for downsampling and 'dur' for moving window duration\n",
    "        'moving_ms' : dict\n",
    "            parameters for 'moving_rms'\n",
    "        'moving_power_ratio' : \n",
    "            parameters for 'moving_power_ratio'\n",
    "        'zscore' :\n",
    "            parameters for 'moving_zscore'\n",
    "        'moving_covar' : \n",
    "            parameters for 'moving_covar'\n",
    "        'moving_sd' : \n",
    "            parameters for 'moving_sd'\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'abs_pow_thresh' : float\n",
    "            absolute power threshold\n",
    "        'rel_pow_thresh' : float\n",
    "            relative power threshold\n",
    "        'covar_thresh' : float\n",
    "            covariance threshold\n",
    "        'corr_thresh' : float\n",
    "            coorelation threshold\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' is nan,\n",
    "        'sel_value' is nan (for consistency with other methods)\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Lacourse, K. et al. J. Neurosci. Meth. (2018).\n",
    "    \"\"\"\n",
    "    # Prepare downsampling\n",
    "    step = opts.windowing['step']\n",
    "    if step:\n",
    "        ds_freq = int(1 / step) # downsampled sampling frequency\n",
    "        opts.tolerance *= step\n",
    "    else:\n",
    "        ds_freq = s_freq\n",
    "    \n",
    "    # Absolute sigma power\n",
    "    dat_sigma = transform_signal(dat_orig, s_freq, 'double_sosbutter', \n",
    "                                 opts.det_butter)\n",
    "    dat_det = transform_signal(dat_sigma, s_freq, 'moving_ms', opts.moving_ms)\n",
    "    dat_det[dat_det <= 0] = 0.000000001 # arbitrarily small value\n",
    "    abs_sig_pow = log10(dat_det)\n",
    "        # Option to adapt the absolute threshold, for low-amplitude recordings\n",
    "    if opts.abs_pow_thresh < 0:\n",
    "        opts.abs_pow_thresh = (mean(abs_sig_pow) - \n",
    "                               opts.abs_pow_thresh * std(abs_sig_pow))\n",
    "    abs_sig_pow = transform_signal(abs_sig_pow, ds_freq, 'smooth', opts.smooth)\n",
    "    \n",
    "    # Relative sigma power\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'moving_power_ratio', \n",
    "                               opts.moving_power_ratio)\n",
    "    dat_det[dat_det <= 0] = 0.000000001\n",
    "    dat_det = log10(dat_det)\n",
    "    rel_sig_pow = transform_signal(dat_det, ds_freq, 'moving_zscore', \n",
    "                                   opts.zscore)\n",
    "    rel_sig_pow = transform_signal(rel_sig_pow, ds_freq, 'smooth', opts.smooth)\n",
    "    \n",
    "    # Sigma covariance\n",
    "    dat_broad = transform_signal(dat_orig, s_freq, 'double_sosbutter', \n",
    "                                 opts.det_butter2)\n",
    "    dat_covar = transform_signal(dat_sigma, s_freq, 'moving_covar', \n",
    "                                 opts.moving_covar, dat2=dat_broad)\n",
    "    dat_det = dat_covar.copy()\n",
    "    dat_det[dat_det < 0] = 0 # negative covariances are discarded\n",
    "    dat_det = log10(dat_det + 1) # add 1 to avoid -inf\n",
    "    sigma_covar = transform_signal(dat_det, ds_freq, 'moving_zscore', \n",
    "                                   opts.zscore)\n",
    "    sigma_covar = transform_signal(sigma_covar, ds_freq, 'smooth', opts.smooth)\n",
    "    \n",
    "    # Sigma correlation\n",
    "    dat_sd_broad = transform_signal(dat_broad, s_freq, 'moving_sd', \n",
    "                                    opts.moving_sd)\n",
    "    dat_sd_sigma = transform_signal(dat_sigma, s_freq, 'moving_sd', \n",
    "                                    opts.moving_sd)\n",
    "    dat_sd_broad[dat_sd_broad == 0] = 0.000000001\n",
    "    dat_sd_sigma[dat_sd_sigma == 0] = 0.000000001\n",
    "    sigma_corr = dat_covar / (dat_sd_broad * dat_sd_sigma)\n",
    "    sigma_corr = transform_signal(sigma_corr, ds_freq, 'smooth', opts.smooth)\n",
    "\n",
    "    # Thresholding\n",
    "    abs_and_cov = logical_and(abs_sig_pow >= opts.abs_pow_thresh,\n",
    "                              sigma_covar >= opts.covar_thresh)\n",
    "    concensus = logical_and.reduce((rel_sig_pow >= opts.rel_pow_thresh,\n",
    "                                    sigma_corr >= opts.corr_thresh,\n",
    "                                    abs_and_cov))                                    \n",
    "    events = detect_events(concensus, 'custom') # at s_freq * 0.1\n",
    "    \n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_sigma, events, time, opts.tolerance)\n",
    "        events = _select_period(events, abs_and_cov) + 1\n",
    "        \n",
    "        if step:\n",
    "            events = events * (s_freq * step) # upsample\n",
    "            events = asarray(around(events), dtype=int)\n",
    "        \n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_sigma, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_sigma,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'abs_pow_thresh': opts.abs_pow_thresh, \n",
    "              'rel_pow_thresh': opts.rel_pow_thresh, \n",
    "              'covar_thresh': opts.covar_thresh,\n",
    "              'corr_thresh': opts.corr_thresh}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_FASST(dat_orig, s_freq, time, opts, submethod='rms'):\n",
    "    \"\"\"Spindle detection based on FASST method, itself based on Moelle et al. \n",
    "    (2002).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_butter' : dict\n",
    "            parameters for 'butter',\n",
    "        'moving_rms' : dict\n",
    "            parameters for 'moving_rms'\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'det_thresh' : float\n",
    "            detection threshold (percentile)\n",
    "    submethod : str\n",
    "        'abs' (rectified) or 'rms' (root-mean-square)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' with nan,\n",
    "        'sel_value' with nan\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Leclercq, Y. et al. Compu. Intel. and Neurosci. (2011).\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'butter', opts.det_butter)\n",
    "    \n",
    "    det_value = percentile(dat_det, opts.det_thresh)\n",
    "    \n",
    "    if submethod == 'abs':\n",
    "        dat_det = transform_signal(dat_det, s_freq, 'abs')\n",
    "    elif submethod == 'rms':\n",
    "        dat_det = transform_signal(dat_det, s_freq, 'moving_rms', \n",
    "                                   opts.moving_rms)\n",
    "        \n",
    "    dat_det = transform_signal(dat_det, s_freq, 'smooth', opts.smooth)\n",
    "    \n",
    "    events = detect_events(dat_det, 'above_thresh', det_value)\n",
    "\n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                               dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': nan}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_UCSD(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection based on the UCSD method\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with the time points for each sample\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        det_wavelet : dict\n",
    "            parameters for 'wavelet_real',\n",
    "        det_thres' : float\n",
    "            detection threshold\n",
    "        sel_wavelet : dict\n",
    "            parameters for 'wavelet_real'\n",
    "        sel_thresh : float\n",
    "            selection threshold\n",
    "        ratio_thresh : float\n",
    "            ratio between power inside and outside spindle band to accept them\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo' with detection value, 'det_value_hi' with nan,\n",
    "        'sel_value' with selection value\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'wavelet_real',\n",
    "                               opts.det_wavelet)\n",
    "\n",
    "    det_value = define_threshold(dat_det, s_freq, 'median+std',\n",
    "                                 opts.det_thresh)\n",
    "\n",
    "    events = detect_events(dat_det, 'maxima', det_value)\n",
    "\n",
    "    dat_sel = transform_signal(dat_orig, s_freq, 'wavelet_real',\n",
    "                               opts.sel_wavelet)\n",
    "    sel_value = define_threshold(dat_sel, s_freq, 'median+std',\n",
    "                                 opts.sel_thresh)\n",
    "    events = select_events(dat_sel, events, 'above_thresh', sel_value)\n",
    "\n",
    "    events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "    events = within_duration(events, time, opts.duration)\n",
    "    events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "    events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "    events = power_ratio(events, dat_orig, s_freq, opts.frequency,\n",
    "                         opts.ratio_thresh)\n",
    "\n",
    "    power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "    powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "    sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                               dat_orig, time, s_freq)\n",
    "\n",
    "    values = {'det_value_lo': det_value, 'sel_value': sel_value}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def detect_Concordia(dat_orig, s_freq, time, opts):\n",
    "    \"\"\"Spindle detection, experimental Concordia method. Similar to Moelle 2011\n",
    "    and Nir2011.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    opts : instance of 'DetectSpindle'\n",
    "        'det_butter' : dict\n",
    "            parameters for 'butter',\n",
    "        'moving_rms' : dict\n",
    "            parameters for 'moving_rms'\n",
    "        'smooth' : dict\n",
    "            parameters for 'smooth'\n",
    "        'det_thresh' : float\n",
    "            low detection threshold\n",
    "        'det_thresh_hi' : float\n",
    "            high detection threshold\n",
    "        'sel_thresh' : float\n",
    "            selection threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of detected spindles\n",
    "    dict\n",
    "        'det_value_lo', 'det_value_hi' with detection values, 'sel_value' with\n",
    "        selection value\n",
    "    float\n",
    "        spindle density, per 30-s epoch\n",
    "    \"\"\"\n",
    "    dat_det = transform_signal(dat_orig, s_freq, 'butter', opts.det_butter)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'moving_rms', opts.moving_rms)\n",
    "    dat_det = transform_signal(dat_det, s_freq, 'smooth', opts.smooth)\n",
    "\n",
    "    det_value_lo = define_threshold(dat_det, s_freq, 'mean+std',\n",
    "                                    opts.det_thresh)\n",
    "    det_value_hi = define_threshold(dat_det, s_freq, 'mean+std',\n",
    "                                    opts.det_thresh_hi)\n",
    "    sel_value = define_threshold(dat_det, s_freq, 'mean+std', opts.sel_thresh)\n",
    "\n",
    "    events = detect_events(dat_det, 'between_thresh',\n",
    "                           value=(det_value_lo, det_value_hi))\n",
    "\n",
    "    if events is not None:\n",
    "        events = _merge_close(dat_det, events, time, opts.tolerance)\n",
    "\n",
    "        events = select_events(dat_det, events, 'above_thresh', sel_value)\n",
    "\n",
    "        events = within_duration(events, time, opts.duration)\n",
    "        events = _merge_close(dat_det, events, time, opts.min_interval)\n",
    "        events = remove_straddlers(events, time, s_freq)\n",
    "\n",
    "        power_peaks = peak_in_power(events, dat_orig, s_freq, opts.power_peaks)\n",
    "        powers = power_in_band(events, dat_orig, s_freq, opts.frequency)\n",
    "        sp_in_chan = make_spindles(events, power_peaks, powers, dat_det,\n",
    "                                   dat_orig, time, s_freq)\n",
    "\n",
    "    else:\n",
    "        lg.info('No spindle found')\n",
    "        sp_in_chan = []\n",
    "\n",
    "    values = {'det_value_lo': det_value_lo, 'sel_value': sel_value}\n",
    "\n",
    "    density = len(sp_in_chan) * s_freq * 30 / len(dat_orig)\n",
    "\n",
    "    return sp_in_chan, values, density\n",
    "\n",
    "\n",
    "def transform_signal(dat, s_freq, method, method_opt=None, dat2=None):\n",
    "    \"\"\"Transform the data using different methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with all the data for one channel\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    method : str\n",
    "        one of 'abs', 'abs_complex', 'butter', 'cdemod', 'cheby2', \n",
    "        'double_butter', 'double_sosbutter', 'gaussian', 'hilbert', \n",
    "        'high_butter', 'low_butter', 'morlet', 'moving_covar', 'moving_ms',\n",
    "        'moving_periodogram', 'moving_power_ratio',  'moving_rms', 'moving_sd', \n",
    "        'moving_zscore', 'remez', 'smooth', 'sosbutter', 'spectrogram', \n",
    "        'wavelet_real'.\n",
    "    method_opt : dict\n",
    "        depends on methods\n",
    "    dat2 : ndarray(dtype='float')\n",
    "        second vector with data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='float')\n",
    "        vector with all the data for one channel\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    double_butter implements an effective bandpass by applying a highpass, \n",
    "    followed by a lowpass. This method reduces filter instability, due to \n",
    "    underlying numerical instability arising from nyquist / freq at low freq.\n",
    "    \n",
    "    Wavelets pass only absolute values already, it does not make sense to store\n",
    "    the complex values.\n",
    "\n",
    "    Methods\n",
    "    -------    \n",
    "    butter has parameters:\n",
    "        freq : tuple of float\n",
    "            low and high values for bandpass\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    cdemod has parameters:\n",
    "        freq : float\n",
    "            carrier frequency for complex demodulation\n",
    "\n",
    "    cheby2 has parameters:\n",
    "        freq : tuple of float\n",
    "            low and high values for bandpass\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    double_butter has parameters:\n",
    "        freq : tuple of float\n",
    "            low and high values for highpass, then lowpass\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    double_sosbutter has parameters:\n",
    "        freq : tuple of float\n",
    "            low and high values for highpass, then lowpass\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    gaussian has parameters:\n",
    "        dur : float\n",
    "            standard deviation of the Gaussian kernel, aka sigma (sec)\n",
    "\n",
    "    high_butter has parameters:\n",
    "        freq : float\n",
    "            Highpass (lowcut) frequency, in Hz\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    low_butter has parameters:\n",
    "        freq : float\n",
    "            Lowpass (highcut) frequency, in Hz\n",
    "        order : int\n",
    "            filter order (will be effecively doubled by filtfilt)\n",
    "\n",
    "    morlet has parameters:\n",
    "        f0 : float\n",
    "            center frequency in Hz\n",
    "        sd : float\n",
    "            standard deviation of frequency\n",
    "        dur : float\n",
    "            window length in number of standard deviations\n",
    "\n",
    "    moving_covar has parameters:\n",
    "        dur : float\n",
    "            duration of the window (sec)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_ms has parameters:\n",
    "        dur : float\n",
    "            duration of the window (sec)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_periodogram has parameters:\n",
    "        dur : float\n",
    "            duration of the z-score sliding window (sec)\n",
    "        freq : tuple of float\n",
    "            frequency range for periodogram (Hz)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_power_ratio has parameters:\n",
    "        dur : float\n",
    "            duration of the z-score sliding window (sec)\n",
    "        freq_narrow : tuple of float\n",
    "            frequency range for the narrowband power (Hz)\n",
    "        freq_broad : tuple of float\n",
    "            frequency range for the broadband power (Hz)\n",
    "        fft_dur : float\n",
    "            duration of the FFT window (sec)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_rms has parameters:\n",
    "        dur : float\n",
    "            duration of the window (sec)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_sd has parameters:\n",
    "        dur : float\n",
    "            duration of the z-score sliding window (sec)\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    moving_zscore has parameters:\n",
    "        dur : float\n",
    "            duration of the z-score sliding window (sec)\n",
    "        pcl_range : tuple of float, or None\n",
    "            if not None, only data within this percentile range will be used \n",
    "            for determining the standard deviation for calculation of the \n",
    "            z-score\n",
    "        step: float\n",
    "            step between consecutive windows (sec)\n",
    "\n",
    "    remez has parameters:\n",
    "        freq : tuple of float\n",
    "            low and high values for bandpass\n",
    "        rolloff : float\n",
    "            bandwidth, in hertz, between stop and pass frequencies\n",
    "        dur : float\n",
    "            dur * s_freq = N, where N is the filter order, a.k.a number of taps\n",
    "\n",
    "    smooth has parameters:\n",
    "        dur : float\n",
    "            duration of the convolution window (sec). For 'triangle', base of \n",
    "            isosceles triangle.\n",
    "\n",
    "    wavelet_real has parameters:\n",
    "        freqs : ndarray\n",
    "            vector of wavelet frequencies for spindle detection\n",
    "        dur : float\n",
    "            duration of the wavelet (sec)\n",
    "        width : float\n",
    "            wavelet width\n",
    "        win : float\n",
    "            moving average window length (sec) of wavelet convolution\n",
    "    \"\"\"\n",
    "    if 'abs' == method:\n",
    "        dat = absolute(dat)\n",
    "\n",
    "    if 'abs_complex' == method:\n",
    "        dat = dat.real**2 + dat.imag**2\n",
    "\n",
    "    if 'butter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        \n",
    "        nyquist = s_freq / 2\n",
    "        Wn = asarray(freq) / nyquist\n",
    "        b, a = butter(N, Wn, btype='bandpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "\n",
    "    if 'cdemod' == method:\n",
    "        carr_freq = method_opt['freq']\n",
    "        \n",
    "        carr_sig = exp(-1j * 2 * pi * carr_freq * arange(0, len(dat)) / s_freq)\n",
    "        dat = dat * carr_sig        \n",
    "\n",
    "    if 'cheby2' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        \n",
    "        Rs = 40\n",
    "        nyquist = s_freq / 2\n",
    "        Wn = asarray(freq) / nyquist\n",
    "        b, a = cheby2(N, Rs, Wn, btype='bandpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "\n",
    "    if 'double_butter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        nyquist = s_freq / 2\n",
    "        \n",
    "        # Highpass\n",
    "        Wn = freq[0] / nyquist\n",
    "        b, a = butter(N, Wn, btype='highpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "        \n",
    "        # Lowpass\n",
    "        Wn = freq[1] / nyquist\n",
    "        b, a = butter(N, Wn, btype='lowpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "\n",
    "    if 'double_sosbutter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        nyquist = s_freq / 2\n",
    "        \n",
    "        # Highpass\n",
    "        Wn = freq[0] / nyquist\n",
    "        sos = butter(N, Wn, btype='highpass', output='sos')\n",
    "        dat = sosfiltfilt(sos, dat)\n",
    "        \n",
    "        # Lowpass\n",
    "        Wn = freq[1] / nyquist\n",
    "        sos = butter(N, Wn, btype='lowpass', output='sos')\n",
    "        dat = sosfiltfilt(sos, dat)\n",
    "\n",
    "    if 'gaussian' == method:\n",
    "        sigma = method_opt['dur']\n",
    "        \n",
    "        dat = gaussian_filter(dat, sigma)        \n",
    "\n",
    "    if 'hilbert' == method:\n",
    "        N = len(dat)\n",
    "        dat = hilbert(dat, N=next_fast_len(N)) # much faster this way\n",
    "        dat = dat[:N] # truncate away zero-padding\n",
    "        \n",
    "    \n",
    "    if 'high_butter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        \n",
    "        nyquist = s_freq / 2\n",
    "        Wn = freq / nyquist\n",
    "        b, a = butter(N, Wn, btype='highpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "        \n",
    "    if 'low_butter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "        \n",
    "        nyquist = s_freq / 2\n",
    "        Wn = freq / nyquist\n",
    "        b, a = butter(N, Wn, btype='lowpass')\n",
    "        dat = filtfilt(b, a, dat)\n",
    "    \n",
    "    if 'morlet' == method:\n",
    "        f0 = method_opt['f0']\n",
    "        sd = method_opt['sd']\n",
    "        dur = method_opt['dur']\n",
    "        output = method_opt['output']\n",
    "\n",
    "        wm = _wmorlet(f0, sd, s_freq, dur)\n",
    "        dat = fftconvolve(dat, wm, mode='same')\n",
    "        if 'absolute' == output:\n",
    "            dat = absolute(dat)            \n",
    "\n",
    "    if 'moving' in method:\n",
    "        dur = method_opt['dur']\n",
    "        halfdur = dur / 2\n",
    "        total_dur = len(dat) / s_freq\n",
    "        last = len(dat) - 1\n",
    "        \n",
    "        if method_opt['step']:\n",
    "            step = method_opt['step']\n",
    "            len_out = int(len(dat) / (step * s_freq))\n",
    "        else:\n",
    "            step = 1 / s_freq\n",
    "            len_out = len(dat)\n",
    "            \n",
    "        out = zeros((len_out))\n",
    "        \n",
    "        if 'moving_covar' == method:            \n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                win1 = dat[beg:end]\n",
    "                win2 = dat2[beg:end]\n",
    "                out[i] = mean((win1 - mean(win1)) * (win2 - mean(win2)))\n",
    "            dat = out\n",
    "            \n",
    "        if 'moving_periodogram' == method:  \n",
    "            nfft = next_fast_len(dur * s_freq)\n",
    "            sf = rfftfreq(nfft, 1 / s_freq)\n",
    "            freq = method_opt['freq']\n",
    "            f0 = asarray([abs(x - freq[0]) for x in sf]).argmin()\n",
    "            f1 = asarray([abs(x - freq[1]) for x in sf]).argmin()\n",
    "            out = zeros((len_out, f1 - f0))\n",
    "            \n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                windat = dat[beg:end]\n",
    "                sf, psd = periodogram(windat, s_freq, 'hann', nfft=nfft,\n",
    "                                       detrend='constant')\n",
    "                out[i, :] = psd[f0:f1]\n",
    "                \n",
    "            dat = out\n",
    "            \n",
    "        if 'moving_power_ratio' == method:\n",
    "            freq1 = method_opt['freq_narrow']\n",
    "            freq2 = method_opt['freq_broad']\n",
    "            fft_dur = method_opt['fft_dur']\n",
    "            nfft = int(s_freq * fft_dur)\n",
    "            \n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                windat = dat[beg:end]\n",
    "                \n",
    "                sf, psd = periodogram(windat, s_freq, 'hann', nfft=nfft,\n",
    "                                       detrend='constant')\n",
    "                f0 = asarray([abs(x - freq1[0]) for x in sf]).argmin()\n",
    "                f1 = asarray([abs(x - freq1[1]) for x in sf]).argmin()\n",
    "                pow1 = sum(psd[f0:f1])\n",
    "                \n",
    "                f0 = asarray([abs(x - freq2[0]) for x in sf]).argmin()\n",
    "                f1 = asarray([abs(x - freq2[1]) for x in sf]).argmin()\n",
    "                pow2 = sum(psd[f0:f1])\n",
    "                \n",
    "                out[i] = pow1 / pow2\n",
    "                \n",
    "            dat = out\n",
    "        \n",
    "        if 'moving_sd' == method:\n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                win = dat[beg:end]\n",
    "                out[i] = std(win)\n",
    "            dat = out\n",
    "        \n",
    "        if 'moving_zscore' == method:        \n",
    "            pcl_range = method_opt['pcl_range']\n",
    "            if pcl_range is not None:\n",
    "                lo = percentile(dat, pcl_range[0])\n",
    "                hi = percentile(dat, pcl_range[1])\n",
    "            \n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                windat = stddat = dat[beg:end]\n",
    "                \n",
    "                if pcl_range is not None:\n",
    "                    stddat = windat[logical_and(windat > lo, windat < hi)]\n",
    "                out[i] = (dat[i] - mean(windat)) / std(stddat)\n",
    "            dat = out\n",
    "        \n",
    "        if method in ['moving_rms', 'moving_ms']:\n",
    "            for i, j in enumerate(arange(0, total_dur, step)[:-1]):\n",
    "                beg = max(0, int((j - halfdur) * s_freq))\n",
    "                end = min(last, int((j + halfdur) * s_freq))\n",
    "                out[i] = mean(square(dat[beg:end]))   \n",
    "            if method == 'moving_rms':\n",
    "                out = sqrt(out)\n",
    "            dat = out\n",
    "    \n",
    "    if 'remez' == method:\n",
    "        Fp1, Fp2 = method_opt['freq']\n",
    "        rolloff = method_opt['rolloff']\n",
    "        dur = method_opt['dur']\n",
    "        \n",
    "        N = int(s_freq * dur)\n",
    "        nyquist = s_freq / 2\n",
    "        Fs1, Fs2 = Fp1 - rolloff, Fp2 + rolloff\n",
    "        dens = 20\n",
    "        bpass = remez(N, [0, Fs1, Fp1, Fp2, Fs2, nyquist], [0, 1, 0], \n",
    "                      grid_density=dens, fs=s_freq)\n",
    "        dat = filtfilt(bpass, 1, dat)\n",
    "\n",
    "    if 'smooth' == method:   \n",
    "        dur = method_opt['dur']\n",
    "        win = method_opt['win']\n",
    "        \n",
    "        if 'flat' in win:\n",
    "            flat = ones(int(dur * s_freq))\n",
    "            H = flat / sum(flat)\n",
    "            \n",
    "            if 'flat_left' == win:\n",
    "                H = concatenate((H, zeros(len(H))))\n",
    "            elif 'flat_right' == win:\n",
    "                H = concatenate((zeros(len(H) - 1), H))\n",
    "            \n",
    "        elif 'triangle' == win:\n",
    "            T = int(dur * s_freq / 2)\n",
    "            a = arange(T, 0, -1)\n",
    "            \n",
    "            H = hstack([a[-1:0:-1], a])\n",
    "            H = H / sum(H)\n",
    "            \n",
    "        dat = fftconvolve(dat, H, mode='same')\n",
    "    \n",
    "    if 'sosbutter' == method:\n",
    "        freq = method_opt['freq']\n",
    "        N = method_opt['order']\n",
    "\n",
    "        nyquist = s_freq / 2\n",
    "        Wn = asarray(freq) / nyquist\n",
    "        sos = butter(N, Wn, btype='bandpass', output='sos')\n",
    "        dat = sosfiltfilt(sos, dat)\n",
    "        \n",
    "    if 'spectrogram' == method:\n",
    "        nperseg = method_opt['dur'] * s_freq\n",
    "        noverlap = method_opt['step'] * s_freq\n",
    "        detrend = method_opt['detrend']\n",
    "        \n",
    "        dat = spectrogram(dat, fs=s_freq, nperseg=nperseg, noverlap=noverlap, \n",
    "                          detrend=detrend)\n",
    "    \n",
    "    if 'wavelet_real' == method:\n",
    "        freqs = method_opt['freqs']\n",
    "        dur = method_opt['dur']\n",
    "        width = method_opt['width']\n",
    "        win = int(method_opt['win'] * s_freq)\n",
    "\n",
    "        wm = _realwavelets(s_freq, freqs, dur, width)\n",
    "        tfr = empty((dat.shape[0], wm.shape[0]))\n",
    "        for i, one_wm in enumerate(wm):\n",
    "            x = abs(fftconvolve(dat, one_wm, mode='same'))\n",
    "            tfr[:, i] = fftconvolve(x, tukey(win), mode='same')\n",
    "        dat = mean(tfr, axis=1)\n",
    "\n",
    "    return dat\n",
    "\n",
    "\n",
    "def define_threshold(dat, s_freq, method, value, nbins=120):\n",
    "    \"\"\"Return the value of the threshold based on relative values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the data after selection-transformation\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    method : str\n",
    "        one of 'mean', 'median', 'std', 'mean+std', 'median+std', 'histmax'\n",
    "    value : float\n",
    "        value to multiply the values for\n",
    "    nbins : int\n",
    "        for histmax method only, number of bins in the histogram\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        threshold in useful units.\n",
    "\n",
    "    \"\"\"\n",
    "    if method == 'mean':\n",
    "        value = value * mean(dat)\n",
    "    elif method == 'median':\n",
    "        value = value * median(dat)\n",
    "    elif method == 'std':\n",
    "        value = value * std(dat)\n",
    "    elif method == 'mean+std':\n",
    "        value = mean(dat) + value * std(dat)\n",
    "    elif method == 'median+std':\n",
    "        value = median(dat) + value * std(dat)\n",
    "    elif method == 'histmax':\n",
    "        hist = histogram(dat, bins=nbins)\n",
    "        idx_maxbin = argmax(hist[0])\n",
    "        maxamp = mean((hist[1][idx_maxbin], hist[1][idx_maxbin + 1]))\n",
    "        value = value * maxamp\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def peaks_in_time(dat, troughs=False):\n",
    "    \"\"\"Find indices of peaks or troughs in data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the data\n",
    "    troughs : bool\n",
    "        if True, will return indices of troughs instead of peaks\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nadarray of int\n",
    "        indices of peaks (or troughs) in dat\n",
    "        \n",
    "    Note\n",
    "    ----\n",
    "    This function does not deal well with flat signal; when the signal is not \n",
    "    increasing, it is assumed to be descreasing. As a result, this function\n",
    "    finds troughs where the signal begins to increase after either decreasing \n",
    "    or remaining constant\n",
    "    \"\"\"\n",
    "    diff_dat = diff(dat)\n",
    "    increasing = zeros(len(diff_dat))\n",
    "    increasing[diff_dat > 0] = 1 # mask for all points where dat is increasing\n",
    "    flipping = diff(increasing) # peaks are -1, troughs are 1, the rest is zero\n",
    "    \n",
    "    target = -1 if not troughs else 1\n",
    "        \n",
    "    return where(flipping == target)[0] + 1\n",
    "\n",
    "\n",
    "def detect_events(dat, method, value=None):\n",
    "    \"\"\"Detect events using 'above_thresh', 'below_thresh' or\n",
    "    'maxima' method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the data after transformation\n",
    "    method : str\n",
    "        'above_thresh', 'below_thresh' or 'maxima'\n",
    "    value : float or tuple of float\n",
    "        for 'above_thresh' or 'below_thresh', it's the value of threshold for\n",
    "        the event detection\n",
    "        for 'between_thresh', it's the lower and upper threshold as tuple\n",
    "        for 'maxima', it's the distance in s from the peak to find a minimum\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "\n",
    "    \"\"\"\n",
    "    if 'thresh' in method or 'custom' == method:\n",
    "\n",
    "        if method == 'above_thresh':\n",
    "            above_det = dat >= value\n",
    "            detected = _detect_start_end(above_det)\n",
    "\n",
    "        if method == 'below_thresh':\n",
    "            below_det = dat < value\n",
    "            detected = _detect_start_end(below_det)\n",
    "\n",
    "        if method == 'between_thresh':\n",
    "            above_det = dat >= value[0]\n",
    "            below_det = dat < value[1]\n",
    "            between_det = logical_and(above_det, below_det)\n",
    "            detected = _detect_start_end(between_det)\n",
    "            \n",
    "        if method == 'custom':\n",
    "            detected = _detect_start_end(dat)\n",
    "\n",
    "        if detected is None:\n",
    "            return None\n",
    "        \n",
    "        if method in ['above_thresh', 'custom']:    \n",
    "            # add the location of the peak in the middle\n",
    "            detected = insert(detected, 1, 0, axis=1)\n",
    "            for i in detected:\n",
    "                i[1] = i[0] + argmax(dat[i[0]:i[2]])\n",
    "\n",
    "        if method in ['below_thresh', 'between_thresh']:\n",
    "            # add the location of the trough in the middle\n",
    "            detected = insert(detected, 1, 0, axis=1)\n",
    "            for i in detected:\n",
    "                i[1] = i[0] + argmin(dat[i[0]:i[2]])\n",
    "\n",
    "    if method == 'maxima':\n",
    "        peaks = argrelmax(dat)[0]\n",
    "        detected = vstack((peaks, peaks, peaks)).T\n",
    "\n",
    "        if value is not None:\n",
    "            detected = detected[dat[peaks] > value, :]\n",
    "\n",
    "    return detected\n",
    "\n",
    "\n",
    "def select_events(dat, detected, method, value):\n",
    "    \"\"\"Select start sample and end sample of the events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the data after selection-transformation\n",
    "    detected : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    method : str\n",
    "        'above_thresh', 'below_thresh', 'below_thresh_positive'\n",
    "    value : float\n",
    "        for 'threshold', it's the value of threshold for the spindle selection.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "\n",
    "    \"\"\"\n",
    "    if method == 'above_thresh':\n",
    "        above_sel = dat >= value\n",
    "        detected = _select_period(detected, above_sel)\n",
    "    elif method == 'below_thresh':\n",
    "        below_sel = dat <= value\n",
    "        detected = _select_period(detected, below_sel)\n",
    "    elif method == 'Ferrarelli2007':\n",
    "        below_sel = dat <= value\n",
    "        positive = dat >= 0\n",
    "        below_sel_positive = invert(logical_and(below_sel, positive))\n",
    "        detected = _select_period(detected, below_sel_positive)\n",
    "    \n",
    "    return detected\n",
    "\n",
    "\n",
    "def merge_close(events, min_interval, merge_to_longer=False):\n",
    "    \"\"\"Merge events that are separated by a less than a minimum interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : list of dict\n",
    "        events with 'start' and 'end' times, from one or several channels.\n",
    "        **Events must be sorted by their start time.**\n",
    "    min_interval : float\n",
    "        minimum delay between consecutive events, in seconds\n",
    "    merge_to_longer : bool (default: False)\n",
    "        If True, info (chan, peak, etc.) from the longer of the 2 events is\n",
    "        kept. Otherwise, info from the earlier onset spindle is kept.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        original events list with close events merged.\n",
    "    \"\"\"\n",
    "    half_iv = min_interval / 2\n",
    "    merged = []\n",
    "\n",
    "    for higher in events:\n",
    "\n",
    "        if not merged:\n",
    "            merged.append(higher)\n",
    "\n",
    "        else:\n",
    "            lower = merged[-1]\n",
    "\n",
    "            if higher['start'] - half_iv <= lower['end'] + half_iv:\n",
    "\n",
    "                if merge_to_longer and (higher['end'] - higher['start'] >\n",
    "                lower['end'] - lower['start']):\n",
    "                    start = min(lower['start'], higher['start'])\n",
    "                    higher.update({'start': start})\n",
    "                    merged[-1] = higher\n",
    "\n",
    "                else:\n",
    "                    end = max(lower['end'], higher['end'])\n",
    "                    merged[-1].update({'end': end})\n",
    "\n",
    "            else:\n",
    "                merged.append(higher)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def within_duration(events, time, limits):\n",
    "    \"\"\"Check whether event is within time limits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x M matrix with start sample first and end samples last on M\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with time points\n",
    "    limits : tuple of float\n",
    "        low and high limit for spindle duration\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x M matrix with start sample first and end samples last on M\n",
    "    \"\"\"\n",
    "    min_dur = max_dur = ones(events.shape[0], dtype=bool)\n",
    "    \n",
    "    if limits[0] is not None:\n",
    "        min_dur = time[events[:, -1] - 1] - time[events[:, 0]] >= limits[0]\n",
    "    \n",
    "    if limits[1] is not None:\n",
    "        max_dur = time[events[:, -1] - 1] - time[events[:, 0]] <= limits[1]\n",
    "\n",
    "    return events[min_dur & max_dur, :]\n",
    "\n",
    "\n",
    "def remove_straddlers(events, time, s_freq, tolerance=0.1):\n",
    "    \"\"\"Reject an event if it straddles a stitch, by comparing its \n",
    "    duration to its timespan.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x M matrix with start, ..., end samples\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with time points\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    tolerance : float, def=0.1\n",
    "        maximum tolerated difference between event duration and timespan\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x M matrix with start , ..., end samples\n",
    "    \"\"\"\n",
    "    dur = (events[:, -1] - 1 - events[:, 0]) / s_freq\n",
    "    continuous = time[events[:, -1] - 1] - time[events[:, 0]] - dur < tolerance\n",
    "    \n",
    "    return events[continuous, :]\n",
    "    \n",
    "\n",
    "\n",
    "def power_ratio(events, dat, s_freq, limits, ratio_thresh):\n",
    "    \"\"\"Estimate the ratio in power between spindle band and lower frequencies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the original data\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    limits : tuple of float\n",
    "        high and low frequencies for spindle band\n",
    "    ratio_thresh : float\n",
    "        ratio between spindle vs non-spindle amplitude\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    In the original matlab script, it uses amplitude, not power.\n",
    "\n",
    "    \"\"\"\n",
    "    ratio = empty(events.shape[0])\n",
    "    for i, one_event in enumerate(events):\n",
    "\n",
    "        x0 = one_event[0]\n",
    "        x1 = one_event[2]\n",
    "\n",
    "        if x0 < 0 or x1 >= len(dat):\n",
    "            ratio[i] = 0\n",
    "\n",
    "        else:\n",
    "            f, Pxx = periodogram(dat[x0:x1], s_freq, scaling='spectrum')\n",
    "            Pxx = sqrt(Pxx)  # use amplitude\n",
    "\n",
    "            freq_sp = (f >= limits[0]) & (f <= limits[1])\n",
    "            freq_nonsp = (f <= limits[1])\n",
    "\n",
    "            ratio[i] = mean(Pxx[freq_sp]) / mean(Pxx[freq_nonsp])\n",
    "\n",
    "    events = events[ratio > ratio_thresh, :]\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def peak_in_power(events, dat, s_freq, method, value=None):\n",
    "    \"\"\"Define peak in power of the signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the original data\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    method : str or None\n",
    "        'peak' or 'interval'. If None, values will be all NaN\n",
    "    value : float\n",
    "        size of the window around peak, or nothing (for 'interval')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='float')\n",
    "        vector with peak frequency\n",
    "\n",
    "    \"\"\"\n",
    "    dat = diff(dat)  # remove 1/f\n",
    "\n",
    "    peak = empty(events.shape[0])\n",
    "    peak.fill(nan)\n",
    "\n",
    "    if method is not None:\n",
    "        for i, one_event in enumerate(events):\n",
    "\n",
    "            if method == 'peak':\n",
    "                x0 = one_event[1] - value / 2 * s_freq\n",
    "                x1 = one_event[1] + value / 2 * s_freq\n",
    "\n",
    "            elif method == 'interval':\n",
    "                x0 = one_event[0]\n",
    "                x1 = one_event[2]\n",
    "\n",
    "            if x0 < 0 or x1 >= len(dat):\n",
    "                peak[i] = nan\n",
    "            else:\n",
    "                f, Pxx = periodogram(dat[x0:x1], s_freq)\n",
    "                idx_peak = Pxx[f < MAX_FREQUENCY_OF_INTEREST].argmax()\n",
    "                peak[i] = f[idx_peak]\n",
    "\n",
    "    return peak\n",
    "\n",
    "\n",
    "def power_in_band(events, dat, s_freq, frequency):\n",
    "    \"\"\"Define power of the signal within frequency band.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the original data\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "    frequency : tuple of float\n",
    "        low and high frequency of spindle band, for window\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='float')\n",
    "        vector with power\n",
    "    \"\"\"\n",
    "    dat = diff(dat)  # remove 1/f\n",
    "\n",
    "    pw = empty(events.shape[0])\n",
    "    pw.fill(nan)\n",
    "\n",
    "    for i, one_event in enumerate(events):\n",
    "\n",
    "        x0 = one_event[0]\n",
    "        x1 = one_event[2]\n",
    "\n",
    "        if x0 < 0 or x1 >= len(dat):\n",
    "            pw[i] = nan\n",
    "        else:\n",
    "            sf, Pxx = periodogram(dat[x0:x1], s_freq)\n",
    "            # find nearest frequencies in sf\n",
    "            b0 = asarray([abs(x - frequency[0]) for x in sf]).argmin()\n",
    "            b1 = asarray([abs(x - frequency[1]) for x in sf]).argmin()\n",
    "            pw[i] = mean(Pxx[b0:b1])\n",
    "\n",
    "    return pw\n",
    "\n",
    "\n",
    "def make_spindles(events, power_peaks, powers, dat_det, dat_orig, time,\n",
    "                  s_freq):\n",
    "    \"\"\"Create dict for each spindle, based on events of time points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    events : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples, and peak frequency\n",
    "    power_peaks : ndarray (dtype='float')\n",
    "        peak in power spectrum for each event\n",
    "    powers : ndarray (dtype='float')\n",
    "        average power in power spectrum for each event\n",
    "    dat_det : ndarray (dtype='float')\n",
    "        vector with the data after detection-transformation (to compute peak)\n",
    "    dat_orig : ndarray (dtype='float')\n",
    "        vector with the raw data on which detection was performed\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with time points\n",
    "    s_freq : float\n",
    "        sampling frequency\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        list of all the spindles, with information about start_time, peak_time,\n",
    "        end_time (s), peak_val (signal units), area_under_curve\n",
    "        (signal units * s), peak_freq (Hz)\n",
    "    \"\"\"\n",
    "    i, events = _remove_duplicate(events, dat_det)\n",
    "    power_peaks = power_peaks[i]\n",
    "\n",
    "    spindles = []\n",
    "    for i, one_peak, one_pwr in zip(events, power_peaks, powers):\n",
    "        one_spindle = {'start': time[i[0]],\n",
    "                       'end': time[i[2] - 1],\n",
    "                       'peak_time': time[i[1]],\n",
    "                       'peak_val_det': dat_det[i[1]],\n",
    "                       'peak_val_orig': dat_orig[i[1]],\n",
    "                       'dur': (i[2] - i[0]) / s_freq,\n",
    "                       'auc_det': sum(dat_det[i[0]:i[2]]) / s_freq,\n",
    "                       'auc_orig': sum(dat_orig[i[0]:i[2]]) / s_freq,\n",
    "                       'rms_det': sqrt(mean(square(dat_det[i[0]:i[2]]))),\n",
    "                       'rms_orig': sqrt(mean(square(dat_orig[i[0]:i[2]]))),\n",
    "                       'power_orig': one_pwr,\n",
    "                       'peak_freq': one_peak,\n",
    "                       'ptp_det': ptp(dat_det[i[0]:i[2]]),\n",
    "                       'ptp_orig': ptp(dat_orig[i[0]:i[2]])\n",
    "                       }\n",
    "        spindles.append(one_spindle)\n",
    "\n",
    "    return spindles\n",
    "\n",
    "\n",
    "def _detect_start_end(true_values):\n",
    "    \"\"\"From ndarray of bool values, return intervals of True values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_values : ndarray (dtype='bool')\n",
    "        array with bool values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x 2 matrix with starting and ending times.\n",
    "    \"\"\"\n",
    "    neg = zeros((1), dtype='bool')\n",
    "    int_values = asarray(concatenate((neg, true_values[:-1], neg)), \n",
    "                         dtype='int')\n",
    "    # must discard last value to avoid axis out of bounds\n",
    "    cross_threshold = diff(int_values)\n",
    "\n",
    "    event_starts = where(cross_threshold == 1)[0]\n",
    "    event_ends = where(cross_threshold == -1)[0]\n",
    "\n",
    "    if len(event_starts):\n",
    "        events = vstack((event_starts, event_ends)).T\n",
    "\n",
    "    else:\n",
    "        events = None\n",
    "\n",
    "    return events\n",
    "\n",
    "\n",
    "def _merge_close(dat, events, time, min_interval):\n",
    "    \"\"\"Merge together events separated by less than a minimum interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dat : ndarray (dtype='float')\n",
    "        vector with the data after selection-transformation\n",
    "    events : ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    time : ndarray (dtype='float')\n",
    "        vector with time points\n",
    "    min_interval : float\n",
    "        minimum delay between consecutive events, in seconds\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray (dtype='int')\n",
    "        N x 3 matrix with start, peak, end samples\n",
    "    \"\"\"\n",
    "    if not events.any():\n",
    "        return events\n",
    "    \n",
    "    no_merge = time[events[1:, 0] - 1] - time[events[:-1, 2]] >= min_interval\n",
    "\n",
    "    if no_merge.any():\n",
    "        begs = concatenate([[events[0, 0]], events[1:, 0][no_merge]])\n",
    "        ends = concatenate([events[:-1, 2][no_merge], [events[-1, 2]]])\n",
    "\n",
    "        new_events = vstack((begs, ends)).T\n",
    "    else:\n",
    "        new_events = asarray([[events[0, 0], events[-1, 2]]])\n",
    "\n",
    "    # add the location of the peak in the middle\n",
    "    new_events = insert(new_events, 1, 0, axis=1)\n",
    "    for i in new_events:\n",
    "        if i[2] - i[0] >= 1:\n",
    "            i[1] = i[0] + argmax(dat[i[0]:i[2]])\n",
    "\n",
    "    return new_events\n",
    "\n",
    "\n",
    "def _wmorlet(f0, sd, sampling_rate, ns=5):\n",
    "    \"\"\"Adapted from nitime\n",
    "\n",
    "    Returns a complex morlet wavelet in the time domain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        f0 : center frequency\n",
    "        sd : standard deviation of frequency\n",
    "        sampling_rate : samplingrate\n",
    "        ns : window length in number of standard deviations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        complex morlet wavelet in the time domain\n",
    "    \"\"\"\n",
    "    st = 1. / (2. * pi * sd)\n",
    "    w_sz = float(int(ns * st * sampling_rate))  # half time window size\n",
    "    t = arange(-w_sz, w_sz + 1, dtype=float) / sampling_rate\n",
    "    w = (exp(-t ** 2 / (2. * st ** 2)) * exp(2j * pi * f0 * t) /\n",
    "         sqrt(sqrt(pi) * st * sampling_rate))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_detect(method, data, freq, mask):\n",
    "    # Extract only the interesting elements from the mask\n",
    "    data_masked = data[mask]\n",
    "\n",
    "    # Get the spindle data from the offline methods\n",
    "    time = np.arange(0, len(data)) / freq\n",
    "    time_masked = time[mask] \n",
    "    if method == \"Lacourse\":\n",
    "        detector = DetectSpindle(method='Lacourse2018')\n",
    "        spindles, _, _ = detect_Lacourse2018(data_masked, freq, time_masked, detector)\n",
    "    elif method == \"Wamsley\":\n",
    "        detector = DetectSpindle(method='Wamsley2012')\n",
    "        spindles, _, _ = detect_Wamsley2012(data_masked, freq, time_masked, detector)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method\")\n",
    "\n",
    "    # # Convert the spindle data to a numpy array\n",
    "    # spindle_result = np.zeros(data.shape)\n",
    "    # for spindle in spindles:\n",
    "    #     start = spindle[\"start\"]\n",
    "    #     end = spindle[\"end\"]\n",
    "    #     # Find index of timestep closest to start and end\n",
    "    #     start_index = np.argmin(np.abs(timesteps - start))\n",
    "    #     end_index = np.argmin(np.abs(timesteps - end))\n",
    "    #     spindle_result[start_index:end_index] = 1\n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from portiloop_software.portiloop_python.ANN.utils import get_configs\n",
    "\n",
    "from portiloop_software.portiloop_python.ANN.data.mass_data import read_pretraining_dataset, read_sleep_staging_labels, read_spindle_trains_labels\n",
    "from portiloop_software.portiloop_python.ANN.models.lstm import get_trained_model\n",
    "import torch\n",
    "\n",
    "\n",
    "experiment_name = 'test_adapation'\n",
    "seed = 42\n",
    "model_path = 'no_att_baseline'\n",
    "subject_id = '01-02-0019'\n",
    "\n",
    "config = get_configs(experiment_name, False, seed)\n",
    "# config['nb_conv_layers'] = 4\n",
    "# config['hidden_size'] = 64\n",
    "# config['nb_rnn_layers'] = 4\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = get_trained_model(config, config['path_models'] / model_path)\n",
    "\n",
    "# Run some testing on subject 1\n",
    "# Load the data\n",
    "labels = read_spindle_trains_labels(config['old_dataset'])\n",
    "ss_labels = read_sleep_staging_labels(config['path_dataset'])\n",
    "# for index, patient_id in enumerate(ss_labels.keys()):\n",
    "\n",
    "config['subject_id'] = subject_id\n",
    "\n",
    "data = read_pretraining_dataset(config['MASS_dir'], patients_to_keep=[subject_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = data[subject_id]['signal']\n",
    "# Get the sleep stage labels for the whole signal \n",
    "ss_labels_subject = np.array(ss_labels[subject_id])\n",
    "# Repeat each label 250 times\n",
    "ss_labels_subject = np.repeat(ss_labels_subject, 250)\n",
    "# Pad the end with '?' to have the same length as the signal\n",
    "ss_labels_subject = np.pad(ss_labels_subject, (0, len(signal) - len(ss_labels_subject)), 'constant', constant_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mask to keep only N2 and N3\n",
    "mask = np.logical_or(ss_labels_subject == '2', ss_labels_subject == '3')\n",
    "freq = 250\n",
    "wonambi_spindle_result = offline_detect(\"Wamsley\", signal, freq, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6364257.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wonambi_spindle_result[-1]['start'] * 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "887"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wonambi_spindle_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def _wmorlet(f0, sd, sampling_rate, ns=5):\n",
    "    \"\"\"Adapted from nitime\n",
    "\n",
    "    Returns a complex morlet wavelet in the time domain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        f0 : center frequency\n",
    "        sd : standard deviation of frequency\n",
    "        sampling_rate : samplingrate\n",
    "        ns : window length in number of standard deviations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        complex morlet wavelet in the time domain\n",
    "    \"\"\"\n",
    "    st = 1. / (2. * np.pi * sd)\n",
    "    w_sz = float(int(ns * st * sampling_rate))  # half time window size\n",
    "    t = np.arange(-w_sz, w_sz + 1, dtype=float) / sampling_rate\n",
    "    w = (np.exp(-t ** 2 / (2. * st ** 2)) * np.exp(2j * np.pi * f0 * t) /\n",
    "         np.sqrt(np.sqrt(np.pi) * st * sampling_rate))\n",
    "    return w\n",
    "\n",
    "def smooth(data, dur, s_freq):\n",
    "    \"\"\" Adapted from Wonambi\n",
    "    Smoothen the data using a flat window\n",
    "    \"\"\"\n",
    "    flat = np.ones(int(dur * s_freq))\n",
    "    H = flat / sum(flat)\n",
    "    data = fftconvolve(data, H, mode='same')\n",
    "    return data\n",
    "\n",
    "def morlet_transform(data, s_freq, morlet_options):\n",
    "    \"\"\" Adapted from Wonambi\n",
    "    Computes the morlet transform of the data\n",
    "    \"\"\"\n",
    "    f0 = morlet_options['f0']\n",
    "    sd = morlet_options['sd']\n",
    "    dur = morlet_options['dur']\n",
    "    output = morlet_options['output']\n",
    "\n",
    "    wm = _wmorlet(f0, sd, s_freq, dur)\n",
    "    data = fftconvolve(data, wm, mode='same')\n",
    "    if 'absolute' == output:\n",
    "        data = np.absolute(data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def detect_wamsley(data, mask, sampling_rate=250):\n",
    "    frequency = (12, 15)\n",
    "    duration = (0.3, 3)\n",
    "    wavelet_options = {'f0': np.mean(frequency),\n",
    "                        'sd': .8,\n",
    "                        'dur': 1.,\n",
    "                        'output': 'complex'\n",
    "                        }\n",
    "    smooth_duration = .1\n",
    "    det_thresh = 4.5\n",
    "    merge_thresh = 0.3\n",
    "    tolerance = 0\n",
    "    min_interval = 0\n",
    "\n",
    "    # First, we transform the signal using wavelet transform\n",
    "    data_detect = data[mask]\n",
    "    timestamps = (np.arange(0, len(data)) / sampling_rate)[mask]\n",
    "    assert len(data_detect) == len(timestamps)\n",
    "    data_detect = morlet_transform(data_detect, sampling_rate, wavelet_options)\n",
    "    data_detect = np.real(data_detect ** 2) ** 2\n",
    "\n",
    "    # Then we smoothen out the signal\n",
    "    data_detect = smooth(data_detect, sampling_rate, smooth_duration)\n",
    "\n",
    "    # Then, we define the threshold\n",
    "    threshold = det_thresh * np.mean(data_detect)\n",
    "\n",
    "    # Then we find the peaks\n",
    "    peaks = data_detect >= threshold\n",
    "    \n",
    "    # # Find all the leading ones and trailing ones and concatenate in a two dimensional array\n",
    "    # spindle_starts = np.where(np.diff(peaks.astype(int)) == 1)[0]\n",
    "    # spindle_ends = np.where(np.diff(peaks.astype(int)) == -1)[0]\n",
    "\n",
    "    # # Merge the events that are too close\n",
    "    # spindle_starts, spindle_ends = merge_events(spindle_starts, spindle_ends, timestamps, merge_thresh)\n",
    "\n",
    "    # # Remove events that are too short or too long\n",
    "    # spindle_starts, spindle_ends = filter_events_time(spindle_starts, spindle_ends, timestamps, duration[0], duration[1])\n",
    "\n",
    "    # # Remove events that are straddling over a mask boundary\n",
    "    events = _detect_start_end(peaks)\n",
    "    # add the location of the peak in the middle\n",
    "    events = np.insert(events, 1, 0, axis=1)\n",
    "    for i in events:\n",
    "        i[1] = i[0] + np.argmax(data_detect[i[0]:i[2]])\n",
    "    events = _merge_close(data_detect, events, timestamps, tolerance)\n",
    "    events = within_duration(events, timestamps, duration)\n",
    "    events = _merge_close(data_detect, events, timestamps, min_interval)\n",
    "    events = remove_straddlers(events, timestamps, sampling_rate)\n",
    "\n",
    "    def to_index(point):\n",
    "        return timestamps[point] * 250\n",
    "    \n",
    "    events = np.vectorize(to_index)(events)\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_wamsley_spindles = detect_wamsley(signal, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6364257., 6364299., 6364347.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_wamsley_spindles[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
