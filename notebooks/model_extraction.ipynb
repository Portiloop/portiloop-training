{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED=1995\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "gru_tf = tf.keras.layers.GRU(\n",
    "    units=5,\n",
    "    return_sequences=True,\n",
    "    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=SEED),\n",
    "    recurrent_initializer=tf.keras.initializers.Orthogonal(seed=SEED),\n",
    "    bias_initializer=tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    ")\n",
    "\n",
    "y_tf = gru_tf(tf.ones((1, 3, 5)), training=False)  # forward pass with ones\n",
    "\n",
    "np.savez(\n",
    "    'tf_model_weights.npz', \n",
    "    gru_kernel=gru_tf.weights[0].numpy(), \n",
    "    gru_recurrent_kernel=gru_tf.weights[1].numpy(),\n",
    "    gru_bias=gru_tf.weights[2].numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED=1995\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "r.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# from speechbrain.nnet.RNN import GRU, LSTM\n",
    "\n",
    "npz_weights = np.load('tf_model_weights.npz')\n",
    "\n",
    "\n",
    "def convert_input_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "    \n",
    "\n",
    "def convert_recurrent_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "\n",
    "\n",
    "def convert_bias_inv(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))\n",
    "\n",
    "\n",
    "gru_pt = torch.nn.GRU(\n",
    "    hidden_size=5,\n",
    "    input_size=5,\n",
    "    num_layers=1,\n",
    "    bidirectional=False,\n",
    "    batch_first=True\n",
    ")\n",
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        p.data = torch.from_numpy(convert_input_kernel_inv(npz_weights['gru_kernel']))\n",
    "    elif 'weight_hh' in pn:\n",
    "        p.data = torch.from_numpy(convert_recurrent_kernel_inv(npz_weights['gru_recurrent_kernel']))\n",
    "    elif 'bias_ih' in pn:\n",
    "        p.data = torch.from_numpy(convert_bias_inv(npz_weights['gru_bias'])[0])\n",
    "    else:\n",
    "        p.data = torch.from_numpy(convert_bias_inv(npz_weights['gru_bias'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_pt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pt, _ = gru_pt(torch.ones(1, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel(kernel):\n",
    "    kernel_z, kernel_r, kernel_h = np.vsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_r.T, kernel_z.T, kernel_h.T), axis=1)\n",
    "\n",
    "def convert_bias(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        kernel = p.data\n",
    "    elif 'weight_hh' in pn:\n",
    "        recurrent_kernel = p.data\n",
    "    elif 'bias_ih' in pn:\n",
    "        bias_ih = p.data\n",
    "    else:\n",
    "        bias_hh = p.data\n",
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_tf.set_weights([convert_kernel(kernel), \n",
    "                    convert_kernel(recurrent_kernel), \n",
    "                    convert_bias(bias)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf = gru_tf(tf.ones((1, 3, 5)), training=False)  # forward pass with ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports:\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import portiloop_software\n",
    "import torch\n",
    "from portiloop_software import run_offline_unlabelled, get_final_model_config_dict, get_trained_model\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv1D, MaxPool1D, GRU\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the portiloop software package:\n",
    "\n",
    "path_software = Path(portiloop_software.__file__).parent.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder containing pre-trained models:\n",
    "\n",
    "path_experiments = path_software / 'experiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration dictionary of the model:\n",
    "\n",
    "config_dict = get_final_model_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run offline inference (on all data points):\n",
    "\n",
    "model_torch = get_trained_model(config_dict, path_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = tf.keras.Sequential()\n",
    "model_keras.add(tf.keras.layers.Reshape((-1, 54, 1)))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "model_keras.add(tf.keras.layers.Reshape((-1, 558)))\n",
    "model_keras.add(GRU(units=7, time_major=False))\n",
    "model_keras.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_keras.build((None, 50, 54))\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_params = [param.detach().numpy() for param in model_torch.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(torch_params):\n",
    "    print(f\"param {i}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "#     print(f\"kernel_r:{kernel_r}\")\n",
    "#     print(f\"kernel_z:{kernel_z}\")\n",
    "#     print(f\"kernel_h:{kernel_h}\")\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "\n",
    "def convert_kernel(kernel):\n",
    "    kernel_z, kernel_r, kernel_h = np.vsplit(kernel, 3)\n",
    "#     print(f\"kernel_r:{kernel_r}\")\n",
    "#     print(f\"kernel_z:{kernel_z}\")\n",
    "#     print(f\"kernel_h:{kernel_h}\")\n",
    "    return np.concatenate((kernel_r.T, kernel_z.T, kernel_h.T), axis=1)\n",
    "\n",
    "def convert_bias(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.layers[8].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack((torch_params[8], torch_params[9]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_params[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_params[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [m for m in model_torch.modules()]\n",
    "gru_pt = l[14]\n",
    "gru_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        kernel = p.data\n",
    "    elif 'weight_hh' in pn:\n",
    "        recurrent_kernel = p.data\n",
    "    elif 'bias_ih' in pn:\n",
    "        bias_ih = p.data\n",
    "    else:\n",
    "        bias_hh = p.data\n",
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.layers[1].set_weights([torch_params[0].T, torch_params[1].T])\n",
    "\n",
    "# Second Conv Layer:\n",
    "model_keras.layers[3].set_weights([torch_params[2].T, torch_params[3].T])\n",
    "\n",
    "# Third Conv Layer:\n",
    "model_keras.layers[5].set_weights([torch_params[4].T, torch_params[5].T])\n",
    "\n",
    "# GRU Layer:\n",
    "\n",
    "# kernel_input = convert_kernel(torch_params[6])\n",
    "# kernel_h = convert_kernel(torch_params[7])\n",
    "# bias = convert_bias(np.stack((torch_params[8], torch_params[9]), axis=0))\n",
    "\n",
    "# model_keras.layers[8].set_weights([kernel_input, \n",
    "#                                    kernel_h, \n",
    "#                                    bias])\n",
    "\n",
    "model_keras.layers[8].set_weights([convert_kernel(kernel), \n",
    "                    convert_kernel(recurrent_kernel), \n",
    "                    convert_bias(bias)])\n",
    "\n",
    "# Dense Layer:\n",
    "model_keras.layers[9].set_weights([torch_params[10].T, torch_params[11].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.layers[8].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numpy = np.ones((1, 50, 54))\n",
    "input_torch = torch.ones((1, 50, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, hn1, _, _ = model_torch(input_torch, None, None, torch.zeros(1, 1, 7), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_keras = model_keras(input_numpy)\n",
    "print(out_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model_keras.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model_keras.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]   # evaluation function\n",
    "\n",
    "# Testing\n",
    "layer_outs = [func([input_numpy]) for func in functors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===\")\n",
    "print(np.array(layer_outs[2]).squeeze().swapaxes(1,2).shape)\n",
    "print(np.array(layer_outs[2]).squeeze().swapaxes(1,2))\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[4]).squeeze().swapaxes(1,2).shape)\n",
    "print(np.array(layer_outs[4]).squeeze().swapaxes(1,2))\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[6]).squeeze().swapaxes(1,2).shape)\n",
    "print(np.array(layer_outs[6]).squeeze().swapaxes(1,2))\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[8]).squeeze().shape)\n",
    "print(np.array(layer_outs[8]).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_tf = model_keras.layers[8]\n",
    "gru_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_pt(torch.ones(1, 50, 558))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf = gru_tf(tf.ones((1, 50, 558)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
