{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED=1995\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "gru_tf = tf.keras.layers.GRU(\n",
    "    units=5,\n",
    "    return_sequences=True,\n",
    "    kernel_initializer=tf.keras.initializers.GlorotUniform(seed=SEED),\n",
    "    recurrent_initializer=tf.keras.initializers.Orthogonal(seed=SEED),\n",
    "    bias_initializer=tf.keras.initializers.GlorotUniform(seed=SEED)\n",
    ")\n",
    "\n",
    "y_tf = gru_tf(tf.ones((1, 3, 5)), training=False)  # forward pass with ones\n",
    "\n",
    "np.savez(\n",
    "    'tf_model_weights.npz', \n",
    "    gru_kernel=gru_tf.weights[0].numpy(), \n",
    "    gru_recurrent_kernel=gru_tf.weights[1].numpy(),\n",
    "    gru_bias=gru_tf.weights[2].numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as r\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED=1995\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "r.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# from speechbrain.nnet.RNN import GRU, LSTM\n",
    "\n",
    "npz_weights = np.load('tf_model_weights.npz')\n",
    "\n",
    "\n",
    "def convert_input_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "    \n",
    "\n",
    "def convert_recurrent_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "\n",
    "\n",
    "def convert_bias_inv(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))\n",
    "\n",
    "\n",
    "gru_pt = torch.nn.GRU(\n",
    "    hidden_size=5,\n",
    "    input_size=5,\n",
    "    num_layers=1,\n",
    "    bidirectional=False,\n",
    "    batch_first=True\n",
    ")\n",
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        p.data = torch.from_numpy(convert_input_kernel_inv(npz_weights['gru_kernel']))\n",
    "    elif 'weight_hh' in pn:\n",
    "        p.data = torch.from_numpy(convert_recurrent_kernel_inv(npz_weights['gru_recurrent_kernel']))\n",
    "    elif 'bias_ih' in pn:\n",
    "        p.data = torch.from_numpy(convert_bias_inv(npz_weights['gru_bias'])[0])\n",
    "    else:\n",
    "        p.data = torch.from_numpy(convert_bias_inv(npz_weights['gru_bias'])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 5), dtype=float32, numpy=\n",
       "array([[[-0.7925101 , -0.40041846,  0.20510904,  0.13561569,\n",
       "          0.28905517],\n",
       "        [-0.9018102 , -0.5436267 ,  0.2940711 ,  0.23402843,\n",
       "          0.48948967],\n",
       "        [-0.9190761 , -0.58599323,  0.34698206,  0.30531275,\n",
       "          0.58507884]]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(5, 5, batch_first=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_pt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pt, _ = gru_pt(torch.ones(1, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.79250997, -0.40041843,  0.20510904,  0.13561571,  0.28905517],\n",
       "         [-0.90181017, -0.54362673,  0.29407114,  0.23402844,  0.48948961],\n",
       "         [-0.91907609, -0.58599323,  0.34698212,  0.30531275,  0.58507884]]],\n",
       "       grad_fn=<TransposeBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel(kernel):\n",
    "    kernel_z, kernel_r, kernel_h = np.vsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_r.T, kernel_z.T, kernel_h.T), axis=1)\n",
    "\n",
    "def convert_bias(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        kernel = p.data\n",
    "    elif 'weight_hh' in pn:\n",
    "        recurrent_kernel = p.data\n",
    "    elif 'bias_ih' in pn:\n",
    "        bias_ih = p.data\n",
    "    else:\n",
    "        bias_hh = p.data\n",
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_tf.set_weights([convert_kernel(kernel), \n",
    "                    convert_kernel(recurrent_kernel), \n",
    "                    convert_bias(bias)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf = gru_tf(tf.ones((1, 3, 5)), training=False)  # forward pass with ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 5), dtype=float32, numpy=\n",
       "array([[[-0.7925101 , -0.40041846,  0.20510904,  0.13561569,\n",
       "          0.28905517],\n",
       "        [-0.9018102 , -0.5436267 ,  0.2940711 ,  0.23402843,\n",
       "          0.48948967],\n",
       "        [-0.9190761 , -0.58599323,  0.34698206,  0.30531275,\n",
       "          0.58507884]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports:\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import portiloop_software\n",
    "import torch\n",
    "from portiloop_software import run_offline_unlabelled, get_final_model_config_dict, get_trained_model\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv1D, MaxPool1D, GRU\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the portiloop software package:\n",
    "\n",
    "path_software = Path(portiloop_software.__file__).parent.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the folder containing pre-trained models:\n",
    "\n",
    "path_experiments = path_software / 'experiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration dictionary of the model:\n",
    "\n",
    "config_dict = get_final_model_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run offline inference (on all data points):\n",
    "\n",
    "model_torch = get_trained_model(config_dict, path_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PortiloopNetwork(\n",
       "  (first_layer_input1): ConvPoolModule(\n",
       "    (conv): Conv1d(1, 31, kernel_size=(7,), stride=(1,))\n",
       "    (pool): MaxPool1d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (seq_input1): Sequential(\n",
       "    (0): ConvPoolModule(\n",
       "      (conv): Conv1d(31, 31, kernel_size=(7,), stride=(1,))\n",
       "      (pool): MaxPool1d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): ConvPoolModule(\n",
       "      (conv): Conv1d(31, 31, kernel_size=(7,), stride=(1,))\n",
       "      (pool): MaxPool1d(kernel_size=7, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (gru_input1): GRU(558, 7, batch_first=True)\n",
       "  (fc): Linear(in_features=7, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─ConvPoolModule: 1-1                    --\n",
      "|    └─Conv1d: 2-1                       248\n",
      "|    └─MaxPool1d: 2-2                    --\n",
      "|    └─Dropout: 2-3                      --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─ConvPoolModule: 2-4               --\n",
      "|    |    └─Conv1d: 3-1                  6,758\n",
      "|    |    └─MaxPool1d: 3-2               --\n",
      "|    |    └─Dropout: 3-3                 --\n",
      "|    └─ConvPoolModule: 2-5               --\n",
      "|    |    └─Conv1d: 3-4                  6,758\n",
      "|    |    └─MaxPool1d: 3-5               --\n",
      "|    |    └─Dropout: 3-6                 --\n",
      "├─GRU: 1-3                               11,907\n",
      "├─Linear: 1-4                            8\n",
      "=================================================================\n",
      "Total params: 25,679\n",
      "Trainable params: 25,679\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─ConvPoolModule: 1-1                    --\n",
       "|    └─Conv1d: 2-1                       248\n",
       "|    └─MaxPool1d: 2-2                    --\n",
       "|    └─Dropout: 2-3                      --\n",
       "├─Sequential: 1-2                        --\n",
       "|    └─ConvPoolModule: 2-4               --\n",
       "|    |    └─Conv1d: 3-1                  6,758\n",
       "|    |    └─MaxPool1d: 3-2               --\n",
       "|    |    └─Dropout: 3-3                 --\n",
       "|    └─ConvPoolModule: 2-5               --\n",
       "|    |    └─Conv1d: 3-4                  6,758\n",
       "|    |    └─MaxPool1d: 3-5               --\n",
       "|    |    └─Dropout: 3-6                 --\n",
       "├─GRU: 1-3                               11,907\n",
       "├─Linear: 1-4                            8\n",
       "=================================================================\n",
       "Total params: 25,679\n",
       "Trainable params: 25,679\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "\n",
    "class ReshapeLayer(keras.layers.Layer):\n",
    "    def init(self, target_shape, kwargs):\n",
    "        super(ReshapeLayer, self).init(kwargs)\n",
    "        self.target_shape = tuple(target_shape)\n",
    "    \n",
    "    def call(self, input):\n",
    "        # desired_shape = (int(tf.shape(input)[0]), ) + self.target_shape\n",
    "        input = tf.transpose(input, perm=[0,1,3,2])\n",
    "        desired_shape = (-1, 50, 558)\n",
    "        print(desired_shape)\n",
    "        return tf.reshape(input, desired_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 50, 558)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_4 (Reshape)         (None, 50, 54, 1)         0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 50, 48, 31)        248       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 50, 42, 31)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 50, 36, 31)        6758      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 50, 30, 31)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 50, 24, 31)        6758      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 50, 18, 31)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " reshape_layer_3 (ReshapeLay  (None, 50, 558)          0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 7)                 11907     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,679\n",
      "Trainable params: 25,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_keras = tf.keras.Sequential()\n",
    "model_keras.add(tf.keras.layers.Reshape((-1, 54, 1)))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "model_keras.add(tf.keras.layers.Conv1D(31, strides=[1], kernel_size=7, activation='relu'))\n",
    "model_keras.add(tf.keras.layers.MaxPooling2D(pool_size=(1, 7), strides=1, padding='valid'))\n",
    "# model_keras.add(tf.keras.layers.Reshape((-1, 558)))\n",
    "model_keras.add(ReshapeLayer())\n",
    "model_keras.add(GRU(units=7, time_major=False))\n",
    "model_keras.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_keras.build((None, 50, 54))\n",
    "model_keras.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.reshape.Reshape at 0x1f269f48a60>,\n",
       " <keras.layers.convolutional.Conv1D at 0x1f269f485e0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f269f0c700>,\n",
       " <keras.layers.convolutional.Conv1D at 0x1f269f48a90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f26a09a1f0>,\n",
       " <keras.layers.convolutional.Conv1D at 0x1f26a091b20>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f26a025a90>,\n",
       " <__main__.ReshapeLayer at 0x1f269ff40a0>,\n",
       " <keras.layers.recurrent_v2.GRU at 0x1f23b09ac40>,\n",
       " <keras.layers.core.dense.Dense at 0x1f26a025220>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_params = [param.detach().numpy() for param in model_torch.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param 0: (31, 1, 7)\n",
      "param 1: (31,)\n",
      "param 2: (31, 31, 7)\n",
      "param 3: (31,)\n",
      "param 4: (31, 31, 7)\n",
      "param 5: (31,)\n",
      "param 6: (21, 558)\n",
      "param 7: (21, 7)\n",
      "param 8: (21,)\n",
      "param 9: (21,)\n",
      "param 10: (1, 7)\n",
      "param 11: (1,)\n"
     ]
    }
   ],
   "source": [
    "for i, param in enumerate(torch_params):\n",
    "    print(f\"param {i}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kernel_inv(kernel):\n",
    "    kernel_r, kernel_z, kernel_h = np.hsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_z.T, kernel_r.T, kernel_h.T))\n",
    "\n",
    "def convert_kernel(kernel):\n",
    "    kernel_z, kernel_r, kernel_h = np.vsplit(kernel, 3)\n",
    "    return np.concatenate((kernel_r.T, kernel_z.T, kernel_h.T), axis=1)\n",
    "\n",
    "def convert_bias(bias):\n",
    "    bias = bias.reshape(2, 3, -1) \n",
    "    return bias[:, [1, 0, 2], :].reshape((2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gru_4/gru_cell_4/kernel:0' shape=(558, 21) dtype=float32, numpy=\n",
       " array([[ 0.05327124, -0.09894805,  0.00713532, ...,  0.01205312,\n",
       "         -0.06069408, -0.09343455],\n",
       "        [-0.01233265, -0.02554357,  0.03764104, ...,  0.07024445,\n",
       "         -0.07787887, -0.06674337],\n",
       "        [-0.0956309 , -0.08267038,  0.09384438, ...,  0.0194696 ,\n",
       "         -0.07562231,  0.08985353],\n",
       "        ...,\n",
       "        [-0.02833054, -0.06810725, -0.03606706, ...,  0.0228232 ,\n",
       "         -0.09247903,  0.0156399 ],\n",
       "        [ 0.09091369, -0.06932283, -0.0614362 , ..., -0.06032607,\n",
       "          0.09116245, -0.06248832],\n",
       "        [-0.01503307, -0.01054647, -0.01854276, ...,  0.03844938,\n",
       "          0.06964526,  0.08984617]], dtype=float32)>,\n",
       " <tf.Variable 'gru_4/gru_cell_4/recurrent_kernel:0' shape=(7, 21) dtype=float32, numpy=\n",
       " array([[ 4.80661392e-02, -2.99714529e-03,  2.10478798e-01,\n",
       "         -3.82894725e-01, -2.11815879e-01,  2.64448673e-01,\n",
       "          3.83128673e-01,  3.33590358e-02, -6.73722923e-02,\n",
       "         -1.89279780e-01,  5.04327044e-02,  1.21283099e-01,\n",
       "         -4.12207276e-01, -7.61454925e-03, -4.10471074e-02,\n",
       "          4.23291773e-02, -5.15609086e-01,  2.87000202e-02,\n",
       "          2.07518071e-01,  2.87830867e-02,  4.93391603e-02],\n",
       "        [-1.38426661e-01,  6.57462701e-02, -9.05709118e-02,\n",
       "          2.27996349e-01, -1.48564145e-01, -8.27413984e-03,\n",
       "         -4.26917523e-01,  6.59575313e-03, -7.87443221e-02,\n",
       "         -2.41176113e-01, -1.93366781e-01,  3.19791615e-01,\n",
       "         -4.51723933e-02,  1.33470714e-01, -2.82366097e-01,\n",
       "          1.80676088e-01, -1.40338734e-01, -2.04368025e-01,\n",
       "          3.17444652e-01,  3.80987108e-01, -2.61249483e-01],\n",
       "        [-1.00982592e-01,  5.87016903e-02, -2.75581777e-01,\n",
       "          3.33323240e-01, -1.38126522e-01,  1.30928442e-01,\n",
       "          5.07336199e-01,  6.19242191e-02,  1.51966782e-02,\n",
       "          3.32954712e-02, -5.71455993e-03, -3.35447900e-02,\n",
       "          2.47954935e-01, -6.81251362e-02,  2.21305743e-01,\n",
       "          8.13084468e-02, -1.79818451e-01, -3.79255682e-01,\n",
       "         -2.22867399e-01,  3.85869563e-01,  5.40273264e-02],\n",
       "        [ 1.04289792e-01, -8.31982270e-02, -5.15624061e-02,\n",
       "          1.46373734e-01, -9.09534544e-02, -4.14229855e-02,\n",
       "          2.85840541e-01, -5.93813717e-01, -2.24997923e-01,\n",
       "          2.36656107e-02, -4.48641181e-01,  1.06473491e-02,\n",
       "          4.69076708e-02, -2.06600517e-01, -3.22309762e-01,\n",
       "          7.62127116e-02,  2.00658292e-02,  2.97511458e-01,\n",
       "         -7.95753151e-02, -5.00529483e-02, -9.43603143e-02],\n",
       "        [-3.19500685e-01,  2.14319929e-01, -4.43336293e-02,\n",
       "         -1.02812514e-01,  2.64274180e-01,  1.26325980e-01,\n",
       "         -7.08777905e-02, -1.03634939e-01,  3.56087208e-01,\n",
       "          4.61567074e-01, -3.26695472e-01, -3.02111030e-01,\n",
       "         -2.59270608e-01, -3.38364504e-02,  4.84858900e-02,\n",
       "          2.98437387e-01, -1.35090396e-01, -6.52894601e-02,\n",
       "          1.01914957e-01,  3.04459818e-02, -8.02274644e-02],\n",
       "        [-7.21675009e-02,  3.73103917e-01, -1.42654553e-01,\n",
       "         -3.40472788e-01, -3.39864761e-01, -4.18713421e-01,\n",
       "         -1.42575264e-01, -1.82988390e-01, -9.45512392e-03,\n",
       "          7.98828900e-02, -6.82610571e-02,  1.13884374e-01,\n",
       "         -1.72599733e-01, -1.10297270e-01,  2.43756756e-01,\n",
       "         -2.76888222e-01,  3.58553156e-02,  8.34741816e-02,\n",
       "         -2.00394854e-01,  3.33121628e-01,  1.14669845e-01],\n",
       "        [ 1.02433540e-01, -4.10662219e-03,  8.76600072e-02,\n",
       "          4.04819638e-01, -1.40146315e-01,  2.39339277e-01,\n",
       "         -2.99432218e-01,  4.58044372e-02, -1.23982929e-01,\n",
       "          2.90349126e-05, -8.04100186e-02, -1.50698707e-01,\n",
       "         -4.98379171e-01, -5.92702366e-02, -5.79337217e-03,\n",
       "         -2.01779798e-01, -1.53502509e-01, -1.19223818e-01,\n",
       "         -5.03775299e-01, -1.41328990e-01,  2.26602778e-02]], dtype=float32)>,\n",
       " <tf.Variable 'gru_4/gru_cell_4/bias:0' shape=(2, 21) dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.layers[8].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02185846, -0.14705312, -0.06134333, -0.21139653, -0.18442982,\n",
       "         0.00979619, -0.14749926, -0.24829413,  1.0149685 ,  0.30653724,\n",
       "        -0.07180233, -0.6962207 , -0.48068357, -0.37287533, -0.01478305,\n",
       "         0.0281016 , -0.29703212, -0.05942979,  0.1469805 ,  0.30490357,\n",
       "         0.17594711],\n",
       "       [-0.05141691, -0.14167127, -0.00835179, -0.31697038,  0.17389293,\n",
       "         0.12304442,  0.03572496, -0.31770235,  0.99044317,  0.0597805 ,\n",
       "        -0.47962168, -0.7721744 , -0.4003129 , -0.18330953,  0.1975466 ,\n",
       "         0.06060247,  0.20888945,  0.0802715 , -0.32268295,  0.0396922 ,\n",
       "        -0.1638425 ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((torch_params[8], torch_params[9]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 558)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_params[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 7)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_params[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(558, 7, batch_first=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [m for m in model_torch.modules()]\n",
    "gru_pt = l[14]\n",
    "gru_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn, p in gru_pt.named_parameters():\n",
    "    if 'weight_ih' in pn:\n",
    "        kernel = p.data\n",
    "    elif 'weight_hh' in pn:\n",
    "        recurrent_kernel = p.data\n",
    "    elif 'bias_ih' in pn:\n",
    "        bias_ih = p.data\n",
    "    else:\n",
    "        bias_hh = p.data\n",
    "bias = np.stack((bias_ih, bias_hh), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras.layers[1].set_weights([torch_params[0].T, torch_params[1].T])\n",
    "\n",
    "# Second Conv Layer:\n",
    "model_keras.layers[3].set_weights([torch_params[2].T, torch_params[3].T])\n",
    "\n",
    "# Third Conv Layer:\n",
    "model_keras.layers[5].set_weights([torch_params[4].T, torch_params[5].T])\n",
    "\n",
    "# GRU Layer:\n",
    "\n",
    "# kernel_input = convert_kernel(torch_params[6])\n",
    "# kernel_h = convert_kernel(torch_params[7])\n",
    "# bias = convert_bias(np.stack((torch_params[8], torch_params[9]), axis=0))\n",
    "\n",
    "# model_keras.layers[8].set_weights([kernel_input, \n",
    "#                                    kernel_h, \n",
    "#                                    bias])\n",
    "\n",
    "model_keras.layers[8].set_weights([convert_kernel(kernel), \n",
    "                    convert_kernel(recurrent_kernel), \n",
    "                    convert_bias(bias)])\n",
    "\n",
    "# Dense Layer:\n",
    "model_keras.layers[9].set_weights([torch_params[10].T, torch_params[11].T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gru_4/gru_cell_4/kernel:0' shape=(558, 21) dtype=float32, numpy=\n",
       " array([[-0.16189827, -0.02721401, -0.00131223, ..., -0.0224664 ,\n",
       "         -0.10324092,  0.9781653 ],\n",
       "        [-0.04380907,  0.07253738, -0.03930822, ..., -0.04212598,\n",
       "         -0.05580707,  0.70585686],\n",
       "        [-0.22128211,  0.04012021, -0.01671478, ..., -0.07443257,\n",
       "         -0.06322375,  0.50437504],\n",
       "        ...,\n",
       "        [-0.11483102, -0.11880854, -0.21867967, ..., -0.04734865,\n",
       "         -0.17091021,  0.05709471],\n",
       "        [-0.38440633, -0.02999607, -0.02425925, ..., -0.0608215 ,\n",
       "         -0.324488  ,  0.04215567],\n",
       "        [-0.3089492 , -0.13285387,  0.00966667, ..., -0.04424573,\n",
       "         -0.311438  ,  0.10411689]], dtype=float32)>,\n",
       " <tf.Variable 'gru_4/gru_cell_4/recurrent_kernel:0' shape=(7, 21) dtype=float32, numpy=\n",
       " array([[-0.25731143,  0.20413998,  0.03256913, -0.12562902, -0.09498331,\n",
       "         -0.04637064,  0.57656753, -0.6201707 ,  0.11997185, -0.385144  ,\n",
       "         -0.16755357, -0.01406851, -0.30629292,  0.84103894,  0.26957858,\n",
       "         -0.23364532,  0.4858145 , -0.19182166, -0.02058285, -0.14663768,\n",
       "          0.20199597],\n",
       "        [-0.08290721, -0.7156107 ,  0.6436561 ,  0.8648586 ,  0.23764145,\n",
       "          0.4843558 ,  0.541567  ,  0.99050075,  0.58542514, -0.37351114,\n",
       "         -0.5361482 , -0.12143751, -0.4020688 ,  0.9570223 ,  0.6181705 ,\n",
       "          0.8609289 ,  0.1446287 ,  0.04311623, -1.0878714 ,  0.4679108 ,\n",
       "          0.5199532 ],\n",
       "        [-0.00129379, -0.3808429 , -0.3010374 ,  0.41121995,  0.30062875,\n",
       "         -0.03313773,  0.09777896, -1.049533  ,  0.05118641, -0.04941377,\n",
       "          0.18696588, -0.67202705, -0.01426913,  0.47784302, -0.40248397,\n",
       "         -0.10835762,  0.7193698 , -0.67076224,  0.56294024, -0.76738054,\n",
       "         -0.06679677],\n",
       "        [-0.383081  , -0.47720516, -0.15077524,  0.3159395 , -0.02226975,\n",
       "         -0.12925296,  0.18289088, -0.06415956,  0.99747765, -0.10408336,\n",
       "          0.23619236, -0.6557599 ,  0.02152075, -0.21043305,  0.16101497,\n",
       "         -1.2776432 ,  0.4523377 ,  0.9240666 , -0.03697446, -0.37980303,\n",
       "          0.2119384 ],\n",
       "        [ 0.47613987,  0.25982323, -0.0247053 ,  0.18450245, -0.1856036 ,\n",
       "          0.12359718,  0.04531681,  0.46495888, -0.46623012,  0.56620854,\n",
       "         -0.0826712 , -0.05039903, -0.10795129,  0.16746247, -0.24384166,\n",
       "          0.47527328,  0.3609554 , -0.3862204 ,  0.24658927,  0.00823306,\n",
       "         -0.38670537],\n",
       "        [-0.22790648,  0.5568326 ,  0.47821113,  0.2174998 ,  0.3589264 ,\n",
       "          0.00234067,  0.35112065,  0.16686618,  0.4407554 , -0.16659576,\n",
       "          0.08327495,  0.25054178,  0.7629469 ,  0.92793316,  0.18923017,\n",
       "         -0.03207939, -0.05671681,  0.22380543, -0.04293799,  0.41144708,\n",
       "         -0.07449327],\n",
       "        [-0.02701967,  0.12061775,  0.15009059,  0.07626069, -0.5685571 ,\n",
       "         -0.1676254 ,  0.00547623, -0.40365946,  0.07156827, -0.19733106,\n",
       "         -0.2179275 ,  0.07091554,  0.11236315,  0.7094855 ,  0.4993342 ,\n",
       "         -0.03916965,  0.7572489 ,  0.08080562, -0.33383942,  0.1061549 ,\n",
       "          0.6750245 ]], dtype=float32)>,\n",
       " <tf.Variable 'gru_4/gru_cell_4/bias:0' shape=(2, 21) dtype=float32, numpy=\n",
       " array([[-0.24829413,  1.0149685 ,  0.30653724, -0.07180233, -0.6962207 ,\n",
       "         -0.48068357, -0.37287533, -0.02185846, -0.14705312, -0.06134333,\n",
       "         -0.21139653, -0.18442982,  0.00979619, -0.14749926, -0.01478305,\n",
       "          0.0281016 , -0.29703212, -0.05942979,  0.1469805 ,  0.30490357,\n",
       "          0.17594711],\n",
       "        [-0.31770235,  0.99044317,  0.0597805 , -0.47962168, -0.7721744 ,\n",
       "         -0.4003129 , -0.18330953, -0.05141691, -0.14167127, -0.00835179,\n",
       "         -0.31697038,  0.17389293,  0.12304442,  0.03572496,  0.1975466 ,\n",
       "          0.06060247,  0.20888945,  0.0802715 , -0.32268295,  0.0396922 ,\n",
       "         -0.1638425 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras.layers[8].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_numpy = np.ones((1, 50, 54))\n",
    "input_torch = torch.ones((1, 50, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(50, 31, 42)\n",
      "DEBUG: x.mean():0.01873699761927128\n",
      "DEBUG: squeezed shape :(50, 31, 42)\n",
      "DEBUG: squeezed x:\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981292 0.20981292 0.20981292 ... 0.20981292 0.20981292 0.20981292]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(50, 31, 30)\n",
      "DEBUG: x.mean():0.00975038856267929\n",
      "DEBUG: squeezed shape :(50, 31, 30)\n",
      "DEBUG: squeezed x:\n",
      "[[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]]\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(50, 31, 18)\n",
      "DEBUG: x.mean():0.010295066982507706\n",
      "DEBUG: squeezed shape :(50, 31, 18)\n",
      "DEBUG: squeezed x:\n",
      "[[[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "DEBUG: GRU input\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(1, 50, 558)\n",
      "DEBUG: x.mean():0.010295066982507706\n",
      "DEBUG: squeezed shape :(50, 558)\n",
      "DEBUG: squeezed x:\n",
      "[[0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]]\n",
      "DEBUG: before FC\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(1, 7)\n",
      "DEBUG: x.mean():0.2577822506427765\n",
      "DEBUG: squeezed shape :(7,)\n",
      "DEBUG: squeezed x:\n",
      "[ 0.7966442  -0.03222394  0.4979974  -0.05747593 -0.29114568 -0.09384963\n",
      "  0.9845294 ]\n",
      "DEBUG: after FC\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(1, 1)\n",
      "DEBUG: x.mean():-2.943443775177002\n",
      "DEBUG: squeezed shape :()\n",
      "DEBUG: squeezed x:\n",
      "-2.943443775177002\n",
      "DEBUG: after sigmoid:\n",
      "DEBUG: =========================\n",
      "DEBUG: x.shape:(1, 1)\n",
      "DEBUG: x.mean():0.050047293305397034\n",
      "DEBUG: squeezed shape :()\n",
      "DEBUG: squeezed x:\n",
      "0.050047293305397034\n"
     ]
    }
   ],
   "source": [
    "x, hn1, _, _, xs_debug = model_torch(input_torch, None, None, torch.zeros(1, 1, 7), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.05004729]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "(50, 31, 18)\n",
      "[[[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "=============================\n",
      "(50, 558)\n",
      "[[0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      " [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]]\n",
      "=============================\n",
      "(1, 50, 558)\n",
      "[[[0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      "  [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      "  [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      "  [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]\n",
      "  [0.08828816 0.08828816 0.08828816 ... 0.         0.         0.        ]]]\n",
      "=============================\n",
      "(1, 50, 7)\n",
      "[[[ 0.664381    0.01015559  0.0085858   0.10364369 -0.24175419\n",
      "    0.18899557  0.8365881 ]\n",
      "  [ 0.8467703   0.00524194  0.12821284  0.19333589 -0.4225073\n",
      "    0.28037903  0.9561775 ]\n",
      "  [ 0.8564986  -0.00946495  0.2137945   0.2456255  -0.43083376\n",
      "    0.24655184  0.98119897]\n",
      "  [ 0.84645855 -0.02770245  0.28298342  0.25920385 -0.39964956\n",
      "    0.16854346  0.9865788 ]\n",
      "  [ 0.83443624 -0.04619643  0.34144154  0.24283276 -0.36414713\n",
      "    0.08111864  0.9872539 ]\n",
      "  [ 0.822671   -0.06282055  0.39029205  0.20653515 -0.33254078\n",
      "    0.00105102  0.9867483 ]\n",
      "  [ 0.8121052  -0.07625346  0.42974788  0.15914214 -0.3066556\n",
      "   -0.06392639  0.9859576 ]\n",
      "  [ 0.8032778  -0.08591935  0.4602189   0.10793994 -0.2866587\n",
      "   -0.11152322  0.98515224]\n",
      "  [ 0.79639125 -0.09187203  0.48256028  0.05854353 -0.27214405\n",
      "   -0.1427048   0.98443866]\n",
      "  [ 0.7913894  -0.09458882  0.49798638  0.0147718  -0.262428\n",
      "   -0.16014104  0.9838638 ]\n",
      "  [ 0.7880529  -0.09474419  0.5078727  -0.0213141  -0.2566852\n",
      "   -0.16711825  0.9834411 ]\n",
      "  [ 0.786084   -0.09303327  0.5135669  -0.04913785 -0.2540508\n",
      "   -0.16684131  0.98316324]\n",
      "  [ 0.7851682  -0.09007039  0.5162605  -0.069179   -0.25370347\n",
      "   -0.1620503   0.98300976]\n",
      "  [ 0.7850144  -0.08634999  0.51692855 -0.0825238  -0.25492316\n",
      "   -0.15486945  0.98295504]\n",
      "  [ 0.7853749  -0.08224533  0.5163214  -0.09049664 -0.25712195\n",
      "   -0.14680749  0.98297304]\n",
      "  [ 0.786053   -0.07802424  0.51498675 -0.09441097 -0.25984973\n",
      "   -0.13884257  0.98304033]\n",
      "  [ 0.7869015  -0.07386979  0.51330423 -0.09543008 -0.26278284\n",
      "   -0.13153915  0.98313785]\n",
      "  [ 0.7878163  -0.06989997  0.5115235  -0.09450905 -0.26570395\n",
      "   -0.12516557  0.983251  ]\n",
      "  [ 0.7887283  -0.06618442  0.5097977  -0.09238805 -0.2684785\n",
      "   -0.11979429  0.98336935]\n",
      "  [ 0.78959495 -0.06275803  0.5082119  -0.08961236 -0.27103305\n",
      "   -0.11538009  0.98348594]\n",
      "  [ 0.79039305 -0.05963147  0.50680494 -0.08656462 -0.27333623\n",
      "   -0.11181591  0.9835964 ]\n",
      "  [ 0.7911129  -0.05679937  0.50558585 -0.08349871 -0.27538434\n",
      "   -0.10896998  0.9836983 ]\n",
      "  [ 0.7917529  -0.05424635  0.5045463  -0.08057176 -0.27719012\n",
      "   -0.10670891  0.9837908 ]\n",
      "  [ 0.79231715 -0.05195151  0.50366825 -0.07787087 -0.2787751\n",
      "   -0.10491067  0.9838737 ]\n",
      "  [ 0.7928123  -0.04989149  0.5029299  -0.07543502 -0.2801645\n",
      "   -0.10347032  0.98394746]\n",
      "  [ 0.7932462  -0.04804261  0.502309   -0.07327152 -0.28138378\n",
      "   -0.10230201  0.9840128 ]\n",
      "  [ 0.7936268  -0.04638219  0.5017849  -0.07136855 -0.28245667\n",
      "   -0.10133784  0.98407066]\n",
      "  [ 0.7939616  -0.04488926  0.5013393  -0.06970373 -0.28340447\n",
      "   -0.100526    0.98412174]\n",
      "  [ 0.7942572  -0.04354494  0.50095695 -0.06825007 -0.28424558\n",
      "   -0.0998279   0.9841671 ]\n",
      "  [ 0.7945196  -0.0423325   0.50062543 -0.06697995 -0.28499547\n",
      "   -0.09921558  0.9842074 ]\n",
      "  [ 0.7947534  -0.04123731  0.5003349  -0.06586711 -0.28566703\n",
      "   -0.09866933  0.98424333]\n",
      "  [ 0.7949629  -0.0402466   0.5000776  -0.06488809 -0.28627083\n",
      "   -0.09817538  0.9842755 ]\n",
      "  [ 0.7951512  -0.03934931  0.4998477  -0.06402253 -0.28681555\n",
      "   -0.09772441  0.98430437]\n",
      "  [ 0.79532117 -0.03853581  0.4996407  -0.06325328 -0.2873083\n",
      "   -0.09731018  0.98433036]\n",
      "  [ 0.795475   -0.0377977   0.49945325 -0.06256615 -0.28775507\n",
      "   -0.09692845  0.9843538 ]\n",
      "  [ 0.79561454 -0.03712762  0.49928275 -0.0619495  -0.28816065\n",
      "   -0.09657618  0.98437494]\n",
      "  [ 0.7957413  -0.03651908  0.4991272  -0.06139389 -0.28852928\n",
      "   -0.0962512   0.98439413]\n",
      "  [ 0.7958566  -0.03596631  0.49898517 -0.06089158 -0.28886446\n",
      "   -0.09595177  0.98441154]\n",
      "  [ 0.7959615  -0.03546418  0.49885532 -0.06043635 -0.28916937\n",
      "   -0.09567638  0.98442733]\n",
      "  [ 0.796057   -0.03500807  0.4987366  -0.06002301 -0.28944665\n",
      "   -0.09542371  0.9844417 ]\n",
      "  [ 0.7961439  -0.03459379  0.49862808 -0.0596472  -0.28969884\n",
      "   -0.09519225  0.98445475]\n",
      "  [ 0.796223   -0.03421758  0.49852902 -0.0593053  -0.2899281\n",
      "   -0.09498078  0.98446655]\n",
      "  [ 0.79629487 -0.033876    0.4984387  -0.05899412 -0.29013646\n",
      "   -0.09478787  0.9844773 ]\n",
      "  [ 0.7963603  -0.03356593  0.49835634 -0.05871089 -0.2903257\n",
      "   -0.09461219  0.98448706]\n",
      "  [ 0.7964197  -0.03328452  0.4982814  -0.05845319 -0.29049757\n",
      "   -0.09445242  0.98449594]\n",
      "  [ 0.7964737  -0.03302917  0.49821317 -0.05821874 -0.2906536\n",
      "   -0.09430731  0.984504  ]\n",
      "  [ 0.7965227  -0.03279751  0.49815115 -0.05800556 -0.29079515\n",
      "   -0.09417558  0.98451126]\n",
      "  [ 0.7965672  -0.03258737  0.49809486 -0.0578118  -0.29092357\n",
      "   -0.09405611  0.98451793]\n",
      "  [ 0.7966076  -0.03239678  0.49804378 -0.05763578 -0.29104006\n",
      "   -0.0939478   0.98452395]\n",
      "  [ 0.7966442  -0.03222394  0.4979974  -0.05747593 -0.29114568\n",
      "   -0.09384963  0.9845294 ]]]\n",
      "=============================\n",
      "(1, 7)\n",
      "[[ 0.7966442  -0.03222394  0.4979974  -0.05747593 -0.29114568 -0.09384963\n",
      "   0.9845294 ]]\n"
     ]
    }
   ],
   "source": [
    "for xd in xs_debug:\n",
    "    print(\"=============================\")\n",
    "    print(xd.shape)\n",
    "    print(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.79664421, -0.03222394,  0.49799740, -0.05747593, -0.29114568,\n",
       "          -0.09384963,  0.98452938]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 50, 558)\n",
      "tf.Tensor([[0.05004734]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "out_keras = model_keras(input_numpy)\n",
    "print(out_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, 50, 558)\n",
      "(-1, 50, 558)\n",
      "(-1, 50, 558)\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "inp = model_keras.input                                           # input placeholder\n",
    "outputs = [layer.output for layer in model_keras.layers]          # all layer outputs\n",
    "functors = [K.function([inp], [out]) for out in outputs]   # evaluation function\n",
    "\n",
    "# Testing\n",
    "layer_outs = [func([input_numpy]) for func in functors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "(50, 31, 42)\n",
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.0898011  0.0898011  0.0898011  ... 0.0898011  0.0898011  0.0898011 ]\n",
      "  ...\n",
      "  [0.02003773 0.02003773 0.02003773 ... 0.02003773 0.02003773 0.02003773]\n",
      "  [0.20981297 0.20981297 0.20981297 ... 0.20981297 0.20981297 0.20981297]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "===\n",
      "(50, 31, 30)\n",
      "[[[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "\n",
      " [[0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.0103266 0.0103266 0.0103266 ... 0.0103266 0.0103266 0.0103266]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  ...\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]\n",
      "  [0.        0.        0.        ... 0.        0.        0.       ]]]\n",
      "===\n",
      "(1, 1, 50, 18, 31)\n",
      "(50, 18, 31)\n",
      "[[[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "\n",
      " [[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "\n",
      " [[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "\n",
      " [[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "\n",
      " [[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  ...\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      "  [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]]\n",
      "compare to\n",
      "(50, 31, 18)\n",
      "[[[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "[[[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.08828816 0.08828816 0.08828816 ... 0.08828816 0.08828816 0.08828816]\n",
      "  [0.11046179 0.11046179 0.11046179 ... 0.11046179 0.11046179 0.11046179]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.03081214 0.03081214 0.03081214 ... 0.03081214 0.03081214 0.03081214]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]]\n",
      "===\n",
      "(50, 558)\n",
      "0.010295066\n",
      "[[0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      " [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      " [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      " ...\n",
      " [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      " [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]\n",
      " [0.08828814 0.11046176 0.         ... 0.03081214 0.         0.        ]]\n",
      "===\n",
      "(7,)\n",
      "[ 0.61592853  0.14224592 -0.07494228 -0.18201146  0.14648148  0.6308197\n",
      "  0.8100449 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"===\")\n",
    "print(np.array(layer_outs[2]).squeeze().swapaxes(1,2).shape)\n",
    "print(np.array(layer_outs[2]).squeeze().swapaxes(1,2))\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[4]).squeeze().swapaxes(1,2).shape)\n",
    "print(np.array(layer_outs[4]).squeeze().swapaxes(1,2))\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[6]).shape)\n",
    "print(np.array(layer_outs[6]).squeeze().shape)\n",
    "print(np.array(layer_outs[6]).squeeze())\n",
    "\n",
    "print(f\"compare to\\n{xs_debug[0].shape}\\n{xs_debug[0]}\\n{xs_debug[0]}\")\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[7]).squeeze().shape)\n",
    "print(np.array(layer_outs[7]).squeeze().mean())\n",
    "print(np.array(layer_outs[7]).squeeze())\n",
    "\n",
    "print(\"===\")\n",
    "print(np.array(layer_outs[8]).squeeze().shape)\n",
    "print(np.array(layer_outs[8]).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent_v2.GRU at 0x1f269f48670>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_tf = model_keras.layers[8]\n",
    "gru_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(558, 7, batch_first=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.00000000e+00,  0.00000000e+00, -4.53531742e-04, -1.00000000e+00,\n",
       "            1.00000000e+00, -9.79106963e-01,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -9.85145569e-04, -1.00000000e+00,\n",
       "            1.00000000e+00, -9.99547601e-01,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.52158737e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -9.99990225e-01,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.05773115e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -9.99999762e-01,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.59357691e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -3.12906504e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -3.66413593e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -4.19890881e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -4.73326445e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -5.26720285e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -5.80078363e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -6.33406639e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -6.86693192e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -7.39938021e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -7.93141127e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -8.46320391e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -8.99457932e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -9.52553749e-03, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.00561976e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.05865002e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.11163855e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.16458535e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.21750236e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.27038360e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.32322311e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.37603283e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.42880082e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.48153305e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.53422356e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.58688426e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.63950920e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.69209242e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.74464583e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.79716349e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.84963942e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.90207362e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -1.95448399e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.00685263e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.05917954e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.11148262e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.16374397e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.21596360e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.26815939e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.32031345e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.37242579e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.42450237e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.47654915e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.52855420e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.58052349e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00],\n",
       "          [ 1.00000000e+00,  0.00000000e+00, -2.63246298e-02, -1.00000000e+00,\n",
       "            1.00000000e+00, -1.00000000e+00,  1.00000000e+00]]],\n",
       "        grad_fn=<TransposeBackward1>),\n",
       " tensor([[[ 1.00000000,  0.00000000, -0.02632463, -1.00000000,  1.00000000,\n",
       "           -1.00000000,  1.00000000]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_pt(torch.ones(1, 50, 558))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tf = gru_tf(tf.ones((1, 50, 558)), training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[ 1.        ,  0.        , -0.02632462, -1.        ,  1.        ,\n",
       "        -1.        ,  1.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 3)\n",
      "tf:(1, 2, 6)\n",
      "[[[ 1  2  3  4  5  6]\n",
      "  [11 12 13 14 15 16]]]\n",
      "pt:torch.Size([1, 2, 6])\n",
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "         [11., 12., 13., 14., 15., 16.]]])\n"
     ]
    }
   ],
   "source": [
    "# tests\n",
    "\n",
    "np_tens = np.array([[[[1,2,3],\n",
    "                    [4,5,6]],\n",
    "                    [[11,12,13],\n",
    "                    [14,15,16]]]])\n",
    "\n",
    "print(f\"{np_tens.shape}\")\n",
    "\n",
    "tf_tens = tf.convert_to_tensor(np_tens)\n",
    "reshape_tf = tf.keras.layers.Reshape((-1, 6))\n",
    "tf_tens = reshape_tf(tf_tens)\n",
    "print(f\"tf:{tf_tens.shape}\\n{tf_tens}\")\n",
    "\n",
    "pt_tens = torch.Tensor(np_tens)\n",
    "\n",
    "pt_tens = torch.flatten(pt_tens, start_dim=1, end_dim=-1)\n",
    "pt_tens = pt_tens.view(1, 2, -1)\n",
    "\n",
    "print(f\"pt:{pt_tens.shape}\\n{pt_tens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "l = np.arange(1,19)\n",
    "ll = np.array([l + i * 100 for i in range(1,32)])\n",
    "lll = np.array([[ll + i * 10000 for i in range(1,51)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_tens = lll\n",
    "\n",
    "print(f\"{np_tens.shape}\")\n",
    "\n",
    "tf_tens = tf.convert_to_tensor(np_tens)\n",
    "reshape_tf = tf.keras.layers.Reshape((-1, 558))\n",
    "tf_tens = reshape_tf(tf_tens)\n",
    "print(f\"tf:{tf_tens.shape}\\n{np.array(tf_tens)}\")\n",
    "\n",
    "pt_tens = torch.Tensor(np_tens)\n",
    "\n",
    "pt_tens = torch.flatten(pt_tens, start_dim=1, end_dim=-1)\n",
    "pt_tens = pt_tens.view(1, 50, -1)\n",
    "\n",
    "print(f\"pt:{pt_tens.shape}\\n{pt_tens.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
