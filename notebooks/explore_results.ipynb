{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/portiloop-training/temp/merged_results_1514.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results into a dictionaries\n",
    "with open(path, \"r\") as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['1'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all the existing keys in the dictionary\n",
    "metrics = ['loss', 'f1', 'precision', 'recall', 'tp', 'fp', 'fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'skip_ss', '01-05-0015', '01-03-0014', '01-05-0013', '01-05-0002', '01-01-0034', '01-03-0019', '01-01-0002', '01-03-0052', '01-03-0048', '01-01-0017', '01-01-0019', '01-02-0010', '01-03-0034', '01-02-0016', '01-01-0022', '01-03-0027', '01-03-0015', '01-03-0021', '01-03-0001', '01-03-0046', '01-01-0003', '01-05-0001', '01-03-0044', '01-01-0038', '01-02-0015', '01-03-0007', '01-01-0024', '01-05-0004', '01-01-0041', '01-01-0032', '01-05-0007', '01-03-0010', '01-03-0030', '01-02-0009', '01-03-0054', '01-01-0010', '01-03-0026', '01-02-0011', '01-03-0028', '01-01-0033'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average(key, experiment):\n",
    "    all_vals = [v[key] for k, v in experiment.items() if k != 'train' and k != 'skip_ss']\n",
    "    return np.mean(all_vals), np.std(all_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4864249103772365, 0.12306300165009529)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_average('f1', results['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4990521808145957, 0.12621496951637884)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_average('f1', results['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_subject(subject):\n",
    "    print(\"Subject: {}\".format(subject))\n",
    "    for metric in metrics:\n",
    "        no_learning = results['0'][subject][metric]\n",
    "        learning = results['1'][subject][metric]\n",
    "        print(\"{}: {} -> {}\".format(metric, no_learning, learning))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 01-05-0015\n",
      "loss: 0.0884846296053789 -> 0.08883974080411959\n",
      "f1: 0.5771458619074201 -> 0.6123334319442488\n",
      "precision: 0.42316602316602314 -> 0.4893511639425458\n",
      "recall: 0.9072847682119205 -> 0.8178807947019867\n",
      "tp: 1096 -> 988\n",
      "fp: 1494 -> 1031\n",
      "fn: 112 -> 220\n",
      "\n",
      "\n",
      "Subject: 01-03-0014\n",
      "loss: 0.06366358081808697 -> 0.06731549544846485\n",
      "f1: 0.6152677508519941 -> 0.6203118367917979\n",
      "precision: 0.47451669595782076 -> 0.5086385625431928\n",
      "recall: 0.8747300215982722 -> 0.7948164146868251\n",
      "tp: 810 -> 736\n",
      "fp: 897 -> 711\n",
      "fn: 116 -> 190\n",
      "\n",
      "\n",
      "Subject: 01-05-0013\n",
      "loss: 0.06820672290568872 -> 0.07803943518957224\n",
      "f1: 0.6213511212129096 -> 0.6280487756885024\n",
      "precision: 0.5033783783783784 -> 0.52322206095791\n",
      "recall: 0.8115468409586056 -> 0.7854030501089324\n",
      "tp: 745 -> 721\n",
      "fp: 735 -> 657\n",
      "fn: 173 -> 197\n",
      "\n",
      "\n",
      "Subject: 01-05-0002\n",
      "loss: 0.06510099526144153 -> 0.06728768145574864\n",
      "f1: 0.49592893652512793 -> 0.49300956085822534\n",
      "precision: 0.4919236417033774 -> 0.4862119013062409\n",
      "recall: 0.5 -> 0.5\n",
      "tp: 335 -> 335\n",
      "fp: 346 -> 354\n",
      "fn: 335 -> 335\n",
      "\n",
      "\n",
      "Subject: 01-01-0034\n",
      "loss: 0.07719957569047915 -> 0.07831612401339756\n",
      "f1: 0.3285420896853393 -> 0.32755030755014863\n",
      "precision: 0.4181184668989547 -> 0.4259927797833935\n",
      "recall: 0.2705749718151071 -> 0.266065388951522\n",
      "tp: 240 -> 236\n",
      "fp: 334 -> 318\n",
      "fn: 647 -> 651\n",
      "\n",
      "\n",
      "Subject: 01-03-0019\n",
      "loss: 0.05060362057175108 -> 0.05236491259109628\n",
      "f1: 0.5934210476568215 -> 0.5971128559156731\n",
      "precision: 0.6388101983002833 -> 0.6408450704225352\n",
      "recall: 0.5540540540540541 -> 0.558968058968059\n",
      "tp: 451 -> 455\n",
      "fp: 255 -> 255\n",
      "fn: 363 -> 359\n",
      "\n",
      "\n",
      "Subject: 01-01-0002\n",
      "loss: 0.05045428352145194 -> 0.05394515948730994\n",
      "f1: 0.513074199956908 -> 0.5068198083568082\n",
      "precision: 0.4912043301759134 -> 0.49232914923291493\n",
      "recall: 0.5369822485207101 -> 0.522189349112426\n",
      "tp: 363 -> 353\n",
      "fp: 376 -> 364\n",
      "fn: 313 -> 323\n",
      "\n",
      "\n",
      "Subject: 01-03-0052\n",
      "loss: 0.07438174754255433 -> 0.07542856950747329\n",
      "f1: 0.44736841621359974 -> 0.45303209978596914\n",
      "precision: 0.5451895043731778 -> 0.5474137931034483\n",
      "recall: 0.3793103448275862 -> 0.38640973630831643\n",
      "tp: 374 -> 381\n",
      "fp: 312 -> 315\n",
      "fn: 612 -> 605\n",
      "\n",
      "\n",
      "Subject: 01-03-0048\n",
      "loss: 0.07538879221288294 -> 0.08506727039371656\n",
      "f1: 0.4947166136708496 -> 0.49282296154509286\n",
      "precision: 0.45656028368794327 -> 0.4533450704225352\n",
      "recall: 0.539832285115304 -> 0.539832285115304\n",
      "tp: 515 -> 515\n",
      "fp: 613 -> 621\n",
      "fn: 439 -> 439\n",
      "\n",
      "\n",
      "Subject: 01-01-0017\n",
      "loss: 0.04361054926181481 -> 0.04526770415301831\n",
      "f1: 0.36194415237818006 -> 0.36024844239839854\n",
      "precision: 0.4498714652956298 -> 0.4484536082474227\n",
      "recall: 0.3027681660899654 -> 0.30103806228373703\n",
      "tp: 175 -> 174\n",
      "fp: 214 -> 214\n",
      "fn: 403 -> 404\n",
      "\n",
      "\n",
      "Subject: 01-01-0019\n",
      "loss: 0.05067714878198403 -> 0.05535597154484229\n",
      "f1: 0.47004607854204006 -> 0.47783933066132867\n",
      "precision: 0.34965719882468166 -> 0.36469344608879495\n",
      "recall: 0.7168674698795181 -> 0.6927710843373494\n",
      "tp: 357 -> 345\n",
      "fp: 664 -> 601\n",
      "fn: 141 -> 153\n",
      "\n",
      "\n",
      "Subject: 01-02-0010\n",
      "loss: 0.11629093745873918 -> 0.11047587164964714\n",
      "f1: 0.5297823556745725 -> 0.5807326957272346\n",
      "precision: 0.36633663366336633 -> 0.4321049974760222\n",
      "recall: 0.9565667011375388 -> 0.8852119958634953\n",
      "tp: 925 -> 856\n",
      "fp: 1600 -> 1125\n",
      "fn: 42 -> 111\n",
      "\n",
      "\n",
      "Subject: 01-03-0034\n",
      "loss: 0.2829129232622342 -> 0.26627549459977673\n",
      "f1: 0.3904969015428028 -> 0.39776194991329084\n",
      "precision: 0.2455808080808081 -> 0.25101647763749196\n",
      "recall: 0.9526530612244898 -> 0.9575510204081633\n",
      "tp: 1167 -> 1173\n",
      "fp: 3585 -> 3500\n",
      "fn: 58 -> 52\n",
      "\n",
      "\n",
      "Subject: 01-02-0016\n",
      "loss: 0.07790431020869829 -> 0.07580617777330687\n",
      "f1: 0.48050770215196503 -> 0.518403313361245\n",
      "precision: 0.3375796178343949 -> 0.3866976024748647\n",
      "recall: 0.8333333333333334 -> 0.7861635220125787\n",
      "tp: 530 -> 500\n",
      "fp: 1040 -> 793\n",
      "fn: 106 -> 136\n",
      "\n",
      "\n",
      "Subject: 01-01-0022\n",
      "loss: 0.07881660257619898 -> 0.07872341885563103\n",
      "f1: 0.07004830613564507 -> 0.0722891535589782\n",
      "precision: 0.1870967741935484 -> 0.1910828025477707\n",
      "recall: 0.04309063893016345 -> 0.04457652303120357\n",
      "tp: 29 -> 30\n",
      "fp: 126 -> 127\n",
      "fn: 644 -> 643\n",
      "\n",
      "\n",
      "Subject: 01-03-0027\n",
      "loss: 0.07302403930347781 -> 0.07443993376948085\n",
      "f1: 0.3362974894835538 -> 0.3407999955018113\n",
      "precision: 0.5024154589371981 -> 0.49882903981264637\n",
      "recall: 0.25273390036452004 -> 0.25880923450789795\n",
      "tp: 208 -> 213\n",
      "fp: 206 -> 214\n",
      "fn: 615 -> 610\n",
      "\n",
      "\n",
      "Subject: 01-03-0015\n",
      "loss: 0.16693365773733979 -> 0.13725765662866982\n",
      "f1: 0.480216572611752 -> 0.5388194912551671\n",
      "precision: 0.32296918767507005 -> 0.3858295334970186\n",
      "recall: 0.9358766233766234 -> 0.8928571428571429\n",
      "tp: 1153 -> 1100\n",
      "fp: 2417 -> 1751\n",
      "fn: 79 -> 132\n",
      "\n",
      "\n",
      "Subject: 01-03-0021\n",
      "loss: 0.2115225208266713 -> 0.19174959231665967\n",
      "f1: 0.4357405105107583 -> 0.4568245088471808\n",
      "precision: 0.28374070138150903 -> 0.3020685746670445\n",
      "recall: 0.9384885764499121 -> 0.9367311072056239\n",
      "tp: 1068 -> 1066\n",
      "fp: 2696 -> 2463\n",
      "fn: 70 -> 72\n",
      "\n",
      "\n",
      "Subject: 01-03-0001\n",
      "loss: 0.05718105464552823 -> 0.057645089184290337\n",
      "f1: 0.5525525477383979 -> 0.5583333284992135\n",
      "precision: 0.6845238095238095 -> 0.6826783114992722\n",
      "recall: 0.46324269889224573 -> 0.47230614300100704\n",
      "tp: 460 -> 469\n",
      "fp: 212 -> 218\n",
      "fn: 533 -> 524\n",
      "\n",
      "\n",
      "Subject: 01-03-0046\n",
      "loss: 0.10039231735245571 -> 0.09955376561066036\n",
      "f1: 0.5511850688234766 -> 0.5754716935995399\n",
      "precision: 0.40095377842993396 -> 0.438663282571912\n",
      "recall: 0.8814516129032258 -> 0.8362903225806452\n",
      "tp: 1093 -> 1037\n",
      "fp: 1633 -> 1327\n",
      "fn: 147 -> 203\n",
      "\n",
      "\n",
      "Subject: 01-01-0003\n",
      "loss: 0.06172982885128317 -> 0.06815973522463267\n",
      "f1: 0.5634796191609047 -> 0.5656478643084587\n",
      "precision: 0.44741754822650903 -> 0.47677793904209\n",
      "recall: 0.7608465608465609 -> 0.6952380952380952\n",
      "tp: 719 -> 657\n",
      "fp: 888 -> 721\n",
      "fn: 226 -> 288\n",
      "\n",
      "\n",
      "Subject: 01-05-0001\n",
      "loss: 0.13172447511236116 -> 0.11961286136871302\n",
      "f1: 0.4563106759949524 -> 0.49159924943586497\n",
      "precision: 0.2990269461077844 -> 0.3313758389261745\n",
      "recall: 0.9626506024096385 -> 0.9518072289156626\n",
      "tp: 799 -> 790\n",
      "fp: 1873 -> 1594\n",
      "fn: 31 -> 40\n",
      "\n",
      "\n",
      "Subject: 01-03-0044\n",
      "loss: 0.08179331250430562 -> 0.08947761522884157\n",
      "f1: 0.5791173257956409 -> 0.5759121175789828\n",
      "precision: 0.46035367940673133 -> 0.4844884488448845\n",
      "recall: 0.7804642166344294 -> 0.7098646034816247\n",
      "tp: 807 -> 734\n",
      "fp: 946 -> 781\n",
      "fn: 227 -> 300\n",
      "\n",
      "\n",
      "Subject: 01-01-0038\n",
      "loss: 0.08925051204605614 -> 0.09095277786101498\n",
      "f1: 0.5732189929031949 -> 0.5831485540666713\n",
      "precision: 0.4312655086848635 -> 0.46714031971580816\n",
      "recall: 0.8544739429695182 -> 0.775811209439528\n",
      "tp: 869 -> 789\n",
      "fp: 1146 -> 900\n",
      "fn: 148 -> 228\n",
      "\n",
      "\n",
      "Subject: 01-02-0015\n",
      "loss: 0.06223420470454411 -> 0.06233908001360242\n",
      "f1: 0.30224524567233724 -> 0.3075601326840141\n",
      "precision: 0.38716814159292035 -> 0.39082969432314413\n",
      "recall: 0.24787535410764872 -> 0.2535410764872521\n",
      "tp: 175 -> 179\n",
      "fp: 277 -> 279\n",
      "fn: 531 -> 527\n",
      "\n",
      "\n",
      "Subject: 01-03-0007\n",
      "loss: 0.13370560226167166 -> 0.1164737716863984\n",
      "f1: 0.48370197487074484 -> 0.48131197083750077\n",
      "precision: 0.3439569536423841 -> 0.3938826466916355\n",
      "recall: 0.8147058823529412 -> 0.6186274509803922\n",
      "tp: 831 -> 631\n",
      "fp: 1585 -> 971\n",
      "fn: 189 -> 389\n",
      "\n",
      "\n",
      "Subject: 01-01-0024\n",
      "loss: 0.06062311682335128 -> 0.06819706632024561\n",
      "f1: 0.607325713861942 -> 0.5960264850965008\n",
      "precision: 0.5410526315789473 -> 0.5529953917050692\n",
      "recall: 0.6921005385996409 -> 0.6463195691202872\n",
      "tp: 771 -> 720\n",
      "fp: 654 -> 582\n",
      "fn: 343 -> 394\n",
      "\n",
      "\n",
      "Subject: 01-05-0004\n",
      "loss: 0.06827469130055314 -> 0.07215562215481353\n",
      "f1: 0.5458089618862214 -> 0.5407261971793241\n",
      "precision: 0.5100182149362478 -> 0.5083025830258303\n",
      "recall: 0.5870020964360587 -> 0.5775681341719078\n",
      "tp: 560 -> 551\n",
      "fp: 538 -> 533\n",
      "fn: 394 -> 403\n",
      "\n",
      "\n",
      "Subject: 01-01-0041\n",
      "loss: 0.06977731352722544 -> 0.06990269188335281\n",
      "f1: 0.09333333084910228 -> 0.09574467833468912\n",
      "precision: 0.3211009174311927 -> 0.32432432432432434\n",
      "recall: 0.054602184087363496 -> 0.056162246489859596\n",
      "tp: 35 -> 36\n",
      "fp: 74 -> 75\n",
      "fn: 606 -> 605\n",
      "\n",
      "\n",
      "Subject: 01-01-0032\n",
      "loss: 0.07131540759718687 -> 0.07848305655030055\n",
      "f1: 0.43769967579826274 -> 0.4444444395804248\n",
      "precision: 0.35309278350515466 -> 0.3815261044176707\n",
      "recall: 0.5756302521008403 -> 0.5322128851540616\n",
      "tp: 411 -> 380\n",
      "fp: 753 -> 616\n",
      "fn: 303 -> 334\n",
      "\n",
      "\n",
      "Subject: 01-05-0007\n",
      "loss: 0.08696616918954246 -> 0.09769011034356327\n",
      "f1: 0.590962436643401 -> 0.5862516164301019\n",
      "precision: 0.4703409621672116 -> 0.49752339020363234\n",
      "recall: 0.7947908445146015 -> 0.7134964483030781\n",
      "tp: 1007 -> 904\n",
      "fp: 1134 -> 913\n",
      "fn: 260 -> 363\n",
      "\n",
      "\n",
      "Subject: 01-03-0010\n",
      "loss: 0.15023003396545026 -> 0.1273205139836349\n",
      "f1: 0.48903560100250865 -> 0.5638911747100981\n",
      "precision: 0.32858048162230674 -> 0.40172278778386844\n",
      "recall: 0.9557603686635945 -> 0.9456221198156682\n",
      "tp: 1037 -> 1026\n",
      "fp: 2119 -> 1528\n",
      "fn: 48 -> 59\n",
      "\n",
      "\n",
      "Subject: 01-03-0030\n",
      "loss: 0.06489901342601652 -> 0.07000210772679802\n",
      "f1: 0.5130111475424269 -> 0.5175438547356879\n",
      "precision: 0.4427131072410632 -> 0.4573643410852713\n",
      "recall: 0.6098484848484849 -> 0.5959595959595959\n",
      "tp: 483 -> 472\n",
      "fp: 608 -> 560\n",
      "fn: 309 -> 320\n",
      "\n",
      "\n",
      "Subject: 01-02-0009\n",
      "loss: 0.10119445564826052 -> 0.0965624113107053\n",
      "f1: 0.5558858459883784 -> 0.5846055936148523\n",
      "precision: 0.3963543874523103 -> 0.42964001870032725\n",
      "recall: 0.9303482587064676 -> 0.9144278606965174\n",
      "tp: 935 -> 919\n",
      "fp: 1424 -> 1220\n",
      "fn: 70 -> 86\n",
      "\n",
      "\n",
      "Subject: 01-03-0054\n",
      "loss: 0.07239055572988373 -> 0.08327810225561205\n",
      "f1: 0.5490056771360314 -> 0.5507575709621471\n",
      "precision: 0.4384571752694271 -> 0.4580970384373031\n",
      "recall: 0.7340930674264008 -> 0.6904083570750238\n",
      "tp: 773 -> 727\n",
      "fp: 990 -> 860\n",
      "fn: 280 -> 326\n",
      "\n",
      "\n",
      "Subject: 01-01-0010\n",
      "loss: 0.06731035219873155 -> 0.07488896860119723\n",
      "f1: 0.6020015349724902 -> 0.6118530836667018\n",
      "precision: 0.47946045370938073 -> 0.5129461161651504\n",
      "recall: 0.8086866597724922 -> 0.7580144777662875\n",
      "tp: 782 -> 733\n",
      "fp: 849 -> 696\n",
      "fn: 185 -> 234\n",
      "\n",
      "\n",
      "Subject: 01-03-0026\n",
      "loss: 0.0789482780564378 -> 0.08751948312444215\n",
      "f1: 0.6270833286203343 -> 0.6368276354594403\n",
      "precision: 0.5058823529411764 -> 0.5585399449035813\n",
      "recall: 0.8246575342465754 -> 0.7406392694063927\n",
      "tp: 903 -> 811\n",
      "fp: 882 -> 641\n",
      "fn: 192 -> 284\n",
      "\n",
      "\n",
      "Subject: 01-02-0011\n",
      "loss: 0.13306262806263092 -> 0.1131043527200906\n",
      "f1: 0.5199326181161671 -> 0.5769230725588381\n",
      "precision: 0.3596116504854369 -> 0.4252763094666026\n",
      "recall: 0.9381965552178319 -> 0.8966565349544073\n",
      "tp: 926 -> 885\n",
      "fp: 1649 -> 1196\n",
      "fn: 61 -> 102\n",
      "\n",
      "\n",
      "Subject: 01-03-0028\n",
      "loss: 0.09061724376394208 -> 0.09609621771348151\n",
      "f1: 0.5443268836990098 -> 0.558083827833878\n",
      "precision: 0.39596602972399153 -> 0.4241504854368932\n",
      "recall: 0.8704784130688448 -> 0.8156359393232205\n",
      "tp: 746 -> 699\n",
      "fp: 1138 -> 949\n",
      "fn: 111 -> 158\n",
      "\n",
      "\n",
      "Subject: 01-01-0033\n",
      "loss: 0.05093702961819825 -> 0.05422975877890663\n",
      "f1: 0.4778761013012961 -> 0.4846625717497954\n",
      "precision: 0.416988416988417 -> 0.43586206896551727\n",
      "recall: 0.5595854922279793 -> 0.5457685664939551\n",
      "tp: 324 -> 316\n",
      "fp: 453 -> 409\n",
      "fn: 255 -> 263\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subject in results[list(results.keys())[0]].keys():\n",
    "    if subject == 'train' or subject == 'skip_ss':\n",
    "        continue\n",
    "    show_subject(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_better(key):\n",
    "    total = 0\n",
    "    for subject in results[list(results.keys())[0]].keys():\n",
    "        if subject == 'train' or subject == 'skip_ss':\n",
    "            continue\n",
    "        no_learning = results['0'][subject][key]\n",
    "        learning = results['1'][subject][key]\n",
    "        if no_learning > learning:\n",
    "            print(subject)\n",
    "            total += 1\n",
    "            print(f\"No learning: {no_learning}\")\n",
    "            print(f\"Learning: { learning}\")\n",
    "        # if no_learning <= learning:\n",
    "        #     total += 1\n",
    "    print(f\"Total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-05-0015\n",
      "No learning: 0.9072847682119205\n",
      "Learning: 0.8178807947019867\n",
      "01-03-0014\n",
      "No learning: 0.8747300215982722\n",
      "Learning: 0.7948164146868251\n",
      "01-05-0013\n",
      "No learning: 0.8115468409586056\n",
      "Learning: 0.7854030501089324\n",
      "01-01-0034\n",
      "No learning: 0.2705749718151071\n",
      "Learning: 0.266065388951522\n",
      "01-01-0002\n",
      "No learning: 0.5369822485207101\n",
      "Learning: 0.522189349112426\n",
      "01-01-0017\n",
      "No learning: 0.3027681660899654\n",
      "Learning: 0.30103806228373703\n",
      "01-01-0019\n",
      "No learning: 0.7168674698795181\n",
      "Learning: 0.6927710843373494\n",
      "01-02-0010\n",
      "No learning: 0.9565667011375388\n",
      "Learning: 0.8852119958634953\n",
      "01-02-0016\n",
      "No learning: 0.8333333333333334\n",
      "Learning: 0.7861635220125787\n",
      "01-03-0015\n",
      "No learning: 0.9358766233766234\n",
      "Learning: 0.8928571428571429\n",
      "01-03-0021\n",
      "No learning: 0.9384885764499121\n",
      "Learning: 0.9367311072056239\n",
      "01-03-0046\n",
      "No learning: 0.8814516129032258\n",
      "Learning: 0.8362903225806452\n",
      "01-01-0003\n",
      "No learning: 0.7608465608465609\n",
      "Learning: 0.6952380952380952\n",
      "01-05-0001\n",
      "No learning: 0.9626506024096385\n",
      "Learning: 0.9518072289156626\n",
      "01-03-0044\n",
      "No learning: 0.7804642166344294\n",
      "Learning: 0.7098646034816247\n",
      "01-01-0038\n",
      "No learning: 0.8544739429695182\n",
      "Learning: 0.775811209439528\n",
      "01-03-0007\n",
      "No learning: 0.8147058823529412\n",
      "Learning: 0.6186274509803922\n",
      "01-01-0024\n",
      "No learning: 0.6921005385996409\n",
      "Learning: 0.6463195691202872\n",
      "01-05-0004\n",
      "No learning: 0.5870020964360587\n",
      "Learning: 0.5775681341719078\n",
      "01-01-0032\n",
      "No learning: 0.5756302521008403\n",
      "Learning: 0.5322128851540616\n",
      "01-05-0007\n",
      "No learning: 0.7947908445146015\n",
      "Learning: 0.7134964483030781\n",
      "01-03-0010\n",
      "No learning: 0.9557603686635945\n",
      "Learning: 0.9456221198156682\n",
      "01-03-0030\n",
      "No learning: 0.6098484848484849\n",
      "Learning: 0.5959595959595959\n",
      "01-02-0009\n",
      "No learning: 0.9303482587064676\n",
      "Learning: 0.9144278606965174\n",
      "01-03-0054\n",
      "No learning: 0.7340930674264008\n",
      "Learning: 0.6904083570750238\n",
      "01-01-0010\n",
      "No learning: 0.8086866597724922\n",
      "Learning: 0.7580144777662875\n",
      "01-03-0026\n",
      "No learning: 0.8246575342465754\n",
      "Learning: 0.7406392694063927\n",
      "01-02-0011\n",
      "No learning: 0.9381965552178319\n",
      "Learning: 0.8966565349544073\n",
      "01-03-0028\n",
      "No learning: 0.8704784130688448\n",
      "Learning: 0.8156359393232205\n",
      "01-01-0033\n",
      "No learning: 0.5595854922279793\n",
      "Learning: 0.5457685664939551\n",
      "Total: 30\n"
     ]
    }
   ],
   "source": [
    "check_better('recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/portiloop-training/notebooks/explore_results.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B206.12.97.14/home/ubuntu/portiloop-training/notebooks/explore_results.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B206.12.97.14/home/ubuntu/portiloop-training/notebooks/explore_results.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(metric)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B206.12.97.14/home/ubuntu/portiloop-training/notebooks/explore_results.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# print(get_average(metric, results['0']))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    print(metric)\n",
    "    # print(get_average(metric, results['0']))\n",
    "    print(get_average(metric, results['0']))\n",
    "    print(get_average(metric, results['1']))\n",
    "    # print(get_average(metric, results['3']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portiloop-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
